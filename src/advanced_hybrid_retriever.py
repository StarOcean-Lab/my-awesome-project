"""
é«˜çº§æ··åˆæ£€ç´¢å™¨
æ•´åˆå¢å¼ºBM25æ£€ç´¢ã€å‘é‡æ£€ç´¢å’ŒRRFèåˆ
å®ç°å…³é”®è¯+å‘é‡æ··åˆæ£€ç´¢çš„ç¬¬ä¸€ä¸ªä¼˜åŒ–ç›®æ ‡
"""

from typing import List, Dict, Tuple, Optional
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from loguru import logger
import os

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from .enhanced_bm25_retriever import EnhancedBM25Retriever
    from .rrf_fusion import RRFFusion, HybridRetrieverWithRRF
except ImportError:
    from enhanced_bm25_retriever import EnhancedBM25Retriever
    from rrf_fusion import RRFFusion, HybridRetrieverWithRRF

class AdvancedHybridRetriever(BaseRetriever):
    """é«˜çº§æ··åˆæ£€ç´¢å™¨ - å®ç°å…³é”®è¯+å‘é‡æ··åˆæ£€ç´¢ä¼˜åŒ–"""
    
    # Pydanticå­—æ®µå£°æ˜
    vectorstore: Optional[object] = None
    documents: List[Document] = []
    vector_weight: float = 0.4
    bm25_weight: float = 0.6
    rrf_k: int = 60
    enable_force_recall: bool = True
    enable_exact_phrase: bool = True
    k: int = 10
    enhanced_bm25: Optional[object] = None
    rrf_fusion: Optional[object] = None
    
    class Config:
        arbitrary_types_allowed = True
    # çˆ¶ç±»åˆå§‹åŒ–
    def __init__(self, 
                 vectorstore,
                 documents: List[Document] = None,
                 vector_weight: float = 0.4,  # é™ä½å‘é‡æƒé‡
                 bm25_weight: float = 0.6,   # æé«˜BM25æƒé‡
                 rrf_k: int = 60,
                 enable_force_recall: bool = True,
                 enable_exact_phrase: bool = True,
                 k: int = 10):
        """
        åˆå§‹åŒ–é«˜çº§æ··åˆæ£€ç´¢å™¨
        
        Args:
            vectorstore: å‘é‡å­˜å‚¨
            documents: æ–‡æ¡£åˆ—è¡¨
            vector_weight: å‘é‡æ£€ç´¢æƒé‡
            bm25_weight: BM25æ£€ç´¢æƒé‡
            rrf_k: RRFèåˆå‚æ•°
            enable_force_recall: æ˜¯å¦å¯ç”¨å¼ºåˆ¶å¬å›
            enable_exact_phrase: æ˜¯å¦å¯ç”¨ç²¾ç¡®çŸ­è¯­åŒ¹é…
            k: é»˜è®¤è¿”å›ç»“æœæ•°é‡
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(
            vectorstore=vectorstore,
            documents=documents if documents else [],
            vector_weight=vector_weight,
            bm25_weight=bm25_weight,
            rrf_k=rrf_k,
            enable_force_recall=enable_force_recall,
            enable_exact_phrase=enable_exact_phrase,
            k=k
        )
        self.vectorstore = vectorstore
        self.documents = documents if documents else []
        self.vector_weight = vector_weight
        self.bm25_weight = bm25_weight
        self.rrf_k = rrf_k
        self.enable_force_recall = enable_force_recall
        self.enable_exact_phrase = enable_exact_phrase
        self.k = k
        
        # åˆå§‹åŒ–å¢å¼ºBM25æ£€ç´¢å™¨
        self.enhanced_bm25 = EnhancedBM25Retriever()
        
        # åˆå§‹åŒ–RRFèåˆå™¨
        self.rrf_fusion = RRFFusion(k=rrf_k)
        
        # æ„å»ºBM25ç´¢å¼•
        self._build_bm25_index()
        
        logger.info(f"é«˜çº§æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  æƒé‡é…ç½®: å‘é‡={vector_weight}, BM25={bm25_weight}")
        logger.info(f"  åŠŸèƒ½é…ç½®: å¼ºåˆ¶å¬å›={enable_force_recall}, ç²¾ç¡®çŸ­è¯­={enable_exact_phrase}")
        logger.info(f"  æ–‡æ¡£æ•°é‡: {len(self.documents)}")
    
    def _build_bm25_index(self):
        """æ„å»ºå¢å¼ºBM25ç´¢å¼•"""
        if not self.documents:
            logger.warning("æ²¡æœ‰æ–‡æ¡£ç”¨äºæ„å»ºBM25ç´¢å¼•")
            return
        
        logger.info("å¼€å§‹æ„å»ºå¢å¼ºBM25ç´¢å¼•...")
        
        # è½¬æ¢æ–‡æ¡£æ ¼å¼
        bm25_docs = []
        for doc in self.documents:
            bm25_doc = {
                'content': doc.page_content,
                'metadata': doc.metadata if hasattr(doc, 'metadata') else {}
            }
            bm25_docs.append(bm25_doc)
        
        # æ„å»ºç´¢å¼•
        self.enhanced_bm25.build_index(bm25_docs)
        logger.info("å¢å¼ºBM25ç´¢å¼•æ„å»ºå®Œæˆ")
    
    def get_relevant_documents(self, query: str) -> List[Document]:
        """
        è·å–ç›¸å…³æ–‡æ¡£ - ä½¿ç”¨é«˜çº§æ··åˆæ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        try:
            logger.info(f"ğŸ” å¼€å§‹é«˜çº§æ··åˆæ£€ç´¢: '{query[:50]}...'")
            
            # 1. å‘é‡æ£€ç´¢
            vector_results = self._vector_search(query, k=self.k*2)
            
            # 2. å¢å¼ºBM25æ£€ç´¢
            bm25_results = self._enhanced_bm25_search(query, k=self.k*2)
            
            # 3. RRFèåˆ
            fused_results = self._rrf_fusion(vector_results, bm25_results, query)
            
            # 4. è½¬æ¢ä¸ºDocumentå¯¹è±¡
            final_docs = self._convert_to_documents(fused_results[:self.k])
            
            # 5. è®°å½•æ£€ç´¢ç»Ÿè®¡
            self._log_retrieval_stats(query, vector_results, bm25_results, final_docs)
            
            return final_docs
            
        except Exception as e:
            logger.error(f"é«˜çº§æ··åˆæ£€ç´¢å¤±è´¥: {e}")
            # é™çº§åˆ°åŸºç¡€å‘é‡æ£€ç´¢
            return self._fallback_vector_search(query)
    
    def _vector_search(self, query: str, k: int) -> List[Tuple]:
        """æ‰§è¡Œå‘é‡æ£€ç´¢"""
        vector_results = []
        
        if self.vectorstore:
            try:
                if hasattr(self.vectorstore, 'similarity_search_with_score'):
                    vector_results = self.vectorstore.similarity_search_with_score(query, k=k)
                elif hasattr(self.vectorstore, 'get_vectorstore'):
                    vs = self.vectorstore.get_vectorstore()
                    if vs and hasattr(vs, 'similarity_search_with_score'):
                        vector_results = vs.similarity_search_with_score(query, k=k)
                    elif vs:
                        docs = vs.similarity_search(query, k=k)
                        vector_results = [(doc, 1.0/(i+1)) for i, doc in enumerate(docs)]
                else:
                    docs = self.vectorstore.similarity_search(query, k=k)
                    vector_results = [(doc, 1.0/(i+1)) for i, doc in enumerate(docs)]
                    
                logger.info(f"ğŸ“Š å‘é‡æ£€ç´¢è¿”å› {len(vector_results)} ä¸ªç»“æœ")
                
            except Exception as e:
                logger.warning(f"å‘é‡æ£€ç´¢å¤±è´¥: {e}")
        
        return vector_results
    
    def _enhanced_bm25_search(self, query: str, k: int) -> List[Tuple]:
        """æ‰§è¡Œå¢å¼ºBM25æ£€ç´¢"""
        bm25_results = []
        
        try:
            # ä½¿ç”¨å¢å¼ºBM25æ£€ç´¢ï¼ˆåŒ…å«å¼ºåˆ¶å¬å›å’Œç²¾ç¡®çŸ­è¯­åŒ¹é…ï¼‰
            raw_results = self.enhanced_bm25.search(query, k=k)
            
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            for doc_dict, score in raw_results:
                doc = Document(
                    page_content=doc_dict.get('content', ''),
                    metadata=doc_dict.get('metadata', {})
                )
                bm25_results.append((doc, score))
            
            logger.info(f"ğŸ“Š å¢å¼ºBM25æ£€ç´¢è¿”å› {len(bm25_results)} ä¸ªç»“æœ")
            
            # æ˜¾ç¤ºå¼ºåˆ¶å¬å›å’Œç²¾ç¡®åŒ¹é…çš„æ–‡æ¡£
            force_recalled_count = 0
            exact_match_count = 0
            for doc, score in bm25_results:
                if doc.metadata.get('force_recalled', False):
                    force_recalled_count += 1
                if doc.metadata.get('exact_match', False):
                    exact_match_count += 1
            
            if force_recalled_count > 0:
                logger.info(f"  ğŸ¯ å¼ºåˆ¶å¬å›æ–‡æ¡£: {force_recalled_count} ä¸ª")
            if exact_match_count > 0:
                logger.info(f"  ğŸ¯ ç²¾ç¡®åŒ¹é…æ–‡æ¡£: {exact_match_count} ä¸ª")
                
        except Exception as e:
            logger.warning(f"å¢å¼ºBM25æ£€ç´¢å¤±è´¥: {e}")
        
        return bm25_results
    
    def _rrf_fusion(self, vector_results: List[Tuple], bm25_results: List[Tuple], query: str) -> List:
        """æ‰§è¡ŒRRFèåˆ"""
        try:
            logger.info("ğŸ”„ å¼€å§‹RRFèåˆ...")
            
            # è®¾ç½®æƒé‡
            weights = {
                'vector': self.vector_weight,
                'bm25': self.bm25_weight
            }
            
            # æ‰§è¡ŒRRFèåˆ
            rrf_results = self.rrf_fusion.fuse_results(
                vector_results=vector_results,
                bm25_results=bm25_results,
                weights=weights
            )
            
            logger.info(f"ğŸ”„ RRFèåˆå®Œæˆï¼Œå¾—åˆ° {len(rrf_results)} ä¸ªç»“æœ")
            
            # æ˜¾ç¤ºèåˆç»Ÿè®¡
            if rrf_results:
                top_result = rrf_results[0]
                fusion_sources = list(top_result.ranks.keys())
                logger.info(f"  Top1èåˆæ¥æº: {fusion_sources}")
            
            return rrf_results
            
        except Exception as e:
            logger.error(f"RRFèåˆå¤±è´¥: {e}")
            # é™çº§ï¼šç®€å•åˆå¹¶å»é‡
            return self._simple_merge(vector_results, bm25_results)
    
    def _simple_merge(self, vector_results: List[Tuple], bm25_results: List[Tuple]) -> List:
        """ç®€å•åˆå¹¶ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        all_docs = {}  # content -> (doc, max_score)
        
        # å¤„ç†å‘é‡ç»“æœ
        for doc, score in vector_results:
            content = doc.page_content
            weighted_score = score * self.vector_weight
            if content not in all_docs or weighted_score > all_docs[content][1]:
                all_docs[content] = (doc, weighted_score)
        
        # å¤„ç†BM25ç»“æœ
        for doc, score in bm25_results:
            content = doc.page_content
            weighted_score = score * self.bm25_weight
            if content not in all_docs or weighted_score > all_docs[content][1]:
                all_docs[content] = (doc, weighted_score)
        
        # æ’åº
        merged_results = list(all_docs.values())
        merged_results.sort(key=lambda x: x[1], reverse=True)
        
        # è½¬æ¢ä¸ºRRFç»“æœæ ¼å¼
        from rrf_fusion import RRFResult
        simple_results = []
        for i, (doc, score) in enumerate(merged_results):
            result = RRFResult(
                content=doc.page_content,
                metadata=doc.metadata,
                original_scores={'merged': score},
                ranks={'merged': i+1},
                rrf_score=score,
                final_rank=i+1
            )
            simple_results.append(result)
        
        return simple_results
    
    def _convert_to_documents(self, rrf_results: List) -> List[Document]:
        """å°†RRFç»“æœè½¬æ¢ä¸ºDocumentå¯¹è±¡"""
        documents = []
        
        for rrf_result in rrf_results:
            # åˆ›å»ºDocumentå¯¹è±¡
            doc = Document(
                page_content=rrf_result.content,
                metadata=rrf_result.metadata.copy()
            )
            
            # æ·»åŠ èåˆä¿¡æ¯åˆ°metadata
            doc.metadata.update({
                'rrf_score': rrf_result.rrf_score,
                'rrf_rank': rrf_result.final_rank,
                'fusion_sources': list(rrf_result.ranks.keys()),
                'original_ranks': rrf_result.ranks,
                'original_scores': rrf_result.original_scores
            })
            
            documents.append(doc)
        
        return documents
    
    def _fallback_vector_search(self, query: str) -> List[Document]:
        """é™çº§å‘é‡æ£€ç´¢"""
        try:
            if self.vectorstore:
                if hasattr(self.vectorstore, 'similarity_search'):
                    return self.vectorstore.similarity_search(query, k=self.k)
                elif hasattr(self.vectorstore, 'get_vectorstore'):
                    vs = self.vectorstore.get_vectorstore()
                    if vs:
                        return vs.similarity_search(query, k=self.k)
        except Exception as e:
            logger.error(f"é™çº§å‘é‡æ£€ç´¢ä¹Ÿå¤±è´¥: {e}")
        
        return []
    
    def _log_retrieval_stats(self, query: str, vector_results: List, bm25_results: List, final_docs: List):
        """è®°å½•æ£€ç´¢ç»Ÿè®¡ä¿¡æ¯"""
        try:
            logger.info("ğŸ“Š é«˜çº§æ··åˆæ£€ç´¢ç»Ÿè®¡:")
            logger.info(f"  æŸ¥è¯¢: '{query[:50]}...'")
            logger.info(f"  å‘é‡æ£€ç´¢: {len(vector_results)} ä¸ªç»“æœ")
            logger.info(f"  BM25æ£€ç´¢: {len(bm25_results)} ä¸ªç»“æœ")
            logger.info(f"  æœ€ç»ˆç»“æœ: {len(final_docs)} ä¸ªæ–‡æ¡£")
            
            # ç»Ÿè®¡æ¥æºåˆ†å¸ƒ
            if final_docs:
                from collections import Counter
                sources = []
                for doc in final_docs:
                    fusion_sources = doc.metadata.get('fusion_sources', [])
                    sources.extend(fusion_sources)
                
                source_counter = Counter(sources)
                logger.info(f"  èåˆæ¥æºåˆ†å¸ƒ: {dict(source_counter)}")
                
                # æ˜¾ç¤ºTop3ç»“æœ
                logger.info("  Top3ç»“æœ:")
                for i, doc in enumerate(final_docs[:3]):
                    source_file = os.path.basename(doc.metadata.get('source', 'unknown'))
                    rrf_score = doc.metadata.get('rrf_score', 0)
                    fusion_sources = doc.metadata.get('fusion_sources', [])
                    preview = doc.page_content[:100].replace('\n', ' ')
                    
                    logger.info(f"    {i+1}. {source_file} (RRF={rrf_score:.4f}, æ¥æº={fusion_sources})")
                    logger.info(f"       å†…å®¹: {preview}...")
        
        except Exception as e:
            logger.warning(f"è®°å½•ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
    
    def get_detailed_results(self, query: str) -> Dict:
        """
        è·å–è¯¦ç»†çš„æ£€ç´¢ç»“æœï¼ˆç”¨äºè°ƒè¯•å’Œåˆ†æï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            åŒ…å«è¯¦ç»†æ£€ç´¢ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # æ‰§è¡Œå„ä¸ªæ£€ç´¢æ­¥éª¤
            vector_results = self._vector_search(query, k=self.k*2)
            bm25_results = self._enhanced_bm25_search(query, k=self.k*2)
            rrf_results = self._rrf_fusion(vector_results, bm25_results, query)
            
            # æ•´ç†è¯¦ç»†ä¿¡æ¯
            detailed_info = {
                'query': query,
                'vector_results': [
                    {
                        'content': doc.page_content[:200],
                        'metadata': doc.metadata,
                        'score': score
                    } for doc, score in vector_results[:5]
                ],
                'bm25_results': [
                    {
                        'content': doc.page_content[:200],
                        'metadata': doc.metadata,
                        'score': score
                    } for doc, score in bm25_results[:5]
                ],
                'rrf_results': [
                    {
                        'content': result.content[:200],
                        'metadata': result.metadata,
                        'rrf_score': result.rrf_score,
                        'ranks': result.ranks,
                        'original_scores': result.original_scores
                    } for result in rrf_results[:5]
                ],
                'fusion_weights': {
                    'vector': self.vector_weight,
                    'bm25': self.bm25_weight
                },
                'retrieval_config': {
                    'rrf_k': self.rrf_k,
                    'enable_force_recall': self.enable_force_recall,
                    'enable_exact_phrase': self.enable_exact_phrase
                }
            }
            
            return detailed_info
            
        except Exception as e:
            logger.error(f"è·å–è¯¦ç»†ç»“æœå¤±è´¥: {e}")
            return {'error': str(e)} 