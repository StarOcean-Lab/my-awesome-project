"""
ç­”æ¡ˆéªŒè¯æ¨¡å—
æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦çœŸå®æ¥æºäºä¸Šä¸‹æ–‡ï¼Œé˜²æ­¢æ¨¡å‹å¹»è§‰
"""

from typing import List, Dict, Set, Tuple, Optional
from dataclasses import dataclass
import re
import jieba
from loguru import logger
from datetime import datetime
import difflib
from collections import Counter

@dataclass
class ValidationResult:
    """éªŒè¯ç»“æœ"""
    hallucination: bool
    missing_info: List[str]
    confidence: float
    supported_facts: List[str]
    unsupported_facts: List[str]
    fact_coverage: float
    validation_details: Dict
    # æ–°å¢ROUGE/BLEUç›¸å…³å­—æ®µ
    rouge_score: float = 0.0
    bleu_score: float = 0.0
    text_overlap_ratio: float = 0.0
    is_off_topic: bool = False

class AnswerValidator:
    """ç­”æ¡ˆéªŒè¯å™¨"""
    
    def __init__(self, 
                 hallucination_threshold: float = 0.2,  # é™ä½å¹»è§‰é˜ˆå€¼åˆ°0.2ï¼Œå‡å°‘å¯¹æ­£ç¡®ç­”æ¡ˆçš„è¯¯åˆ¤
                 fact_similarity_threshold: float = 0.6,  # é™ä½äº‹å®ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå¯¹ç®€çŸ­ç­”æ¡ˆæ›´å‹å¥½
                 # æ–°å¢é‡å åº¦é˜ˆå€¼
                 rouge_threshold: float = 0.3,
                 bleu_threshold: float = 0.2,
                 overlap_threshold: float = 0.25):
        """
        åˆå§‹åŒ–ç­”æ¡ˆéªŒè¯å™¨
        
        Args:
            hallucination_threshold: å¹»è§‰æ£€æµ‹é˜ˆå€¼
            fact_similarity_threshold: äº‹å®ç›¸ä¼¼åº¦é˜ˆå€¼
            rouge_threshold: ROUGEåˆ†æ•°é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è®¤ä¸ºå¯èƒ½è·‘é¢˜
            bleu_threshold: BLEUåˆ†æ•°é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è®¤ä¸ºå¯èƒ½è·‘é¢˜
            overlap_threshold: æ–‡æœ¬é‡å åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è®¤ä¸ºå¯èƒ½è·‘é¢˜
        """
        self.hallucination_threshold = hallucination_threshold
        self.fact_similarity_threshold = fact_similarity_threshold
        self.rouge_threshold = rouge_threshold
        self.bleu_threshold = bleu_threshold
        self.overlap_threshold = overlap_threshold
        
        # äº‹å®æå–æ¨¡å¼
        self.fact_patterns = {
            "æ—¶é—´": [
                r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥',
                r'\d{4}å¹´\d{1,2}æœˆ',
                r'\d{1,2}æœˆ\d{1,2}æ—¥',
                r'\d{4}-\d{1,2}-\d{1,2}',
                r'æˆªæ­¢æ—¶é—´.*?\d',
                r'å¼€å§‹æ—¶é—´.*?\d',
                r'ç»“æŸæ—¶é—´.*?\d'
            ],
            "æ•°é‡": [
                r'\d+ä¸ª',
                r'\d+é¡¹',
                r'\d+ç±»',
                r'\d+ç§',
                r'å…±\d+',
                r'æ€»è®¡\d+',
                r'æ€»å…±\d+'
            ],
            "è”ç³»æ–¹å¼": [
                r'\d{3,4}-?\d{7,8}',  # ç”µè¯
                r'\w+@\w+\.\w+',      # é‚®ç®±
                r'QQ[:ï¼š]\s*\d+',     # QQ
                r'å¾®ä¿¡[:ï¼š]\s*\w+'     # å¾®ä¿¡
            ],
            "åœ°ç‚¹": [
                r'\w+çœ\w+å¸‚',
                r'\w+å¸‚\w+åŒº',
                r'\w+å¤§å­¦',
                r'\w+å­¦é™¢',
                r'\w+ä¸­å¿ƒ'
            ],
            "åç§°": [
                r'[ã€Š""]([^ã€‹""]{2,20})[ã€‹""]',  # å¼•å·å†…å®¹
                r'ä¸“é¡¹èµ›',
                r'ç«èµ›',
                r'å¤§èµ›',
                r'æŒ‘æˆ˜èµ›'
            ]
        }
        
        # å¦å®šè¯æ±‡
        self.negation_words = {
            'ä¸', 'é', 'æ— ', 'æ²¡æœ‰', 'ç¼ºå°‘', 'ç¼ºä¹', 'æœª', 'å¦', 'ç¦æ­¢', 'æ‹’ç»'
        }
        
        logger.info("ç­”æ¡ˆéªŒè¯å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def calculate_rouge_score(self, answer: str, context: str) -> float:
        """
        è®¡ç®—ROUGEåˆ†æ•°ï¼ˆåŸºäº1-gramé‡å ï¼‰
        
        Args:
            answer: ç”Ÿæˆçš„ç­”æ¡ˆ
            context: æºæ–‡æ¡£ä¸Šä¸‹æ–‡
            
        Returns:
            ROUGE-1åˆ†æ•°
        """
        try:
            # åˆ†è¯
            answer_tokens = set(jieba.lcut(answer.lower()))
            context_tokens = set(jieba.lcut(context.lower()))
            
            # ç§»é™¤åœç”¨è¯
            stopwords = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'éƒ½', 'ä¸€', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä¼š', 'ç€', 'çœ‹', 'å¥½', 'è¿™', 'é‚£', 'ä¸', 'æˆ–', 'ä½†'}
            answer_tokens = answer_tokens - stopwords
            context_tokens = context_tokens - stopwords
            
            if not answer_tokens:
                return 0.0
            
            # è®¡ç®—é‡å 
            overlap = answer_tokens.intersection(context_tokens)
            rouge_score = len(overlap) / len(answer_tokens)
            
            return rouge_score
            
        except Exception as e:
            logger.warning(f"ROUGEè®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_bleu_score(self, answer: str, context: str) -> float:
        """
        è®¡ç®—ç®€åŒ–çš„BLEUåˆ†æ•°ï¼ˆåŸºäº2-gramé‡å ï¼‰
        
        Args:
            answer: ç”Ÿæˆçš„ç­”æ¡ˆ
            context: æºæ–‡æ¡£ä¸Šä¸‹æ–‡
            
        Returns:
            ç®€åŒ–BLEUåˆ†æ•°
        """
        try:
            # åˆ†è¯
            answer_tokens = jieba.lcut(answer.lower())
            context_tokens = jieba.lcut(context.lower())
            
            # ç§»é™¤åœç”¨è¯
            stopwords = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'éƒ½', 'ä¸€', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä¼š', 'ç€', 'çœ‹', 'å¥½', 'è¿™', 'é‚£', 'ä¸', 'æˆ–', 'ä½†'}
            answer_tokens = [token for token in answer_tokens if token not in stopwords]
            context_tokens = [token for token in context_tokens if token not in stopwords]
            
            if len(answer_tokens) < 2:
                return 0.0
            
            # ç”Ÿæˆ2-gram
            answer_bigrams = set()
            for i in range(len(answer_tokens) - 1):
                answer_bigrams.add((answer_tokens[i], answer_tokens[i + 1]))
            
            context_bigrams = set()
            for i in range(len(context_tokens) - 1):
                context_bigrams.add((context_tokens[i], context_tokens[i + 1]))
            
            if not answer_bigrams:
                return 0.0
            
            # è®¡ç®—é‡å 
            overlap = answer_bigrams.intersection(context_bigrams)
            bleu_score = len(overlap) / len(answer_bigrams)
            
            return bleu_score
            
        except Exception as e:
            logger.warning(f"BLEUè®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_text_overlap_ratio(self, answer: str, context: str) -> float:
        """
        è®¡ç®—æ–‡æœ¬é‡å åº¦æ¯”ä¾‹
        
        Args:
            answer: ç”Ÿæˆçš„ç­”æ¡ˆ
            context: æºæ–‡æ¡£ä¸Šä¸‹æ–‡
            
        Returns:
            æ–‡æœ¬é‡å åº¦æ¯”ä¾‹
        """
        try:
            # ä½¿ç”¨å­—ç¬¦çº§åˆ«çš„é‡å è®¡ç®—
            answer_chars = set(answer.lower().replace(' ', '').replace('\n', ''))
            context_chars = set(context.lower().replace(' ', '').replace('\n', ''))
            
            if not answer_chars:
                return 0.0
            
            overlap = answer_chars.intersection(context_chars)
            overlap_ratio = len(overlap) / len(answer_chars)
            
            return overlap_ratio
            
        except Exception as e:
            logger.warning(f"æ–‡æœ¬é‡å åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0

    def validate_answer(self, question: str, answer: str, context: str) -> ValidationResult:
        """
        æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦çœŸå®æ¥æºäºä¸Šä¸‹æ–‡
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            answer: LLMç”Ÿæˆçš„ç­”æ¡ˆ
            context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
            
        Returns:
            ValidationResult: éªŒè¯ç»“æœ
        """
        logger.info(f"å¼€å§‹éªŒè¯ç­”æ¡ˆï¼Œé—®é¢˜: {question[:50]}...")
        
        # 1. è®¡ç®—ROUGE/BLEUåˆ†æ•°
        rouge_score = self.calculate_rouge_score(answer, context)
        bleu_score = self.calculate_bleu_score(answer, context)
        text_overlap_ratio = self.calculate_text_overlap_ratio(answer, context)
        
        logger.debug(f"ROUGEåˆ†æ•°: {rouge_score:.3f}, BLEUåˆ†æ•°: {bleu_score:.3f}, é‡å åº¦: {text_overlap_ratio:.3f}")
        
        # 2. åŸºäºé‡å åº¦åˆ¤æ–­æ˜¯å¦è·‘é¢˜
        is_off_topic = (rouge_score < self.rouge_threshold and 
                       bleu_score < self.bleu_threshold and 
                       text_overlap_ratio < self.overlap_threshold)
        
        # 3. æå–ç­”æ¡ˆä¸­çš„å…³é”®äº‹å®ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ä½œä¸ºè¡¥å……ï¼‰
        answer_facts = self._extract_facts(answer)
        context_facts = self._extract_facts(context)
        
        # 4. æ£€æŸ¥äº‹å®æ”¯æŒåº¦
        supported_facts, unsupported_facts = self._check_fact_support(
            answer_facts, context_facts
        )
        
        # 5. æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±ä¿¡æ¯
        missing_info = self._check_missing_info(question, answer, context)
        
        # 6. è®¡ç®—ç»¼åˆç½®ä¿¡åº¦ï¼ˆç»“åˆé‡å åº¦å’Œäº‹å®æ”¯æŒåº¦ï¼‰
        confidence = self._calculate_comprehensive_confidence(
            rouge_score, bleu_score, text_overlap_ratio,
            answer_facts, supported_facts, unsupported_facts
        )
        
        # 7. åˆ¤æ–­æ˜¯å¦æœ‰å¹»è§‰ï¼ˆä¸»è¦åŸºäºé‡å åº¦ï¼‰
        hallucination = is_off_topic or confidence < self.hallucination_threshold
        
        # 8. è®¡ç®—äº‹å®è¦†ç›–ç‡
        fact_coverage = len(supported_facts) / len(answer_facts) if answer_facts else 1.0
        
        # 9. æ„å»ºéªŒè¯è¯¦æƒ…
        validation_details = self._build_validation_details(
            answer, context, answer_facts, context_facts, 
            supported_facts, unsupported_facts, rouge_score, bleu_score, text_overlap_ratio
        )
        
        result = ValidationResult(
            hallucination=hallucination,
            missing_info=missing_info,
            confidence=confidence,
            supported_facts=supported_facts,
            unsupported_facts=unsupported_facts,
            fact_coverage=fact_coverage,
            validation_details=validation_details,
            rouge_score=rouge_score,
            bleu_score=bleu_score,
            text_overlap_ratio=text_overlap_ratio,
            is_off_topic=is_off_topic
        )
        
        logger.info(f"éªŒè¯å®Œæˆï¼Œç½®ä¿¡åº¦: {confidence:.3f}, è·‘é¢˜: {is_off_topic}, å¹»è§‰: {hallucination}")
        return result
    
    def _extract_facts(self, text: str) -> List[str]:
        """æå–æ–‡æœ¬ä¸­çš„å…³é”®äº‹å®"""
        facts = []
        
        # ä½¿ç”¨æ­£åˆ™æ¨¡å¼æå–ç»“æ„åŒ–äº‹å®
        for fact_type, patterns in self.fact_patterns.items():
            for pattern in patterns:
                matches = re.findall(pattern, text)
                for match in matches:
                    if isinstance(match, tuple):
                        match = match[0] if match else ""
                    if match and match not in facts:
                        facts.append(match.strip())
        
        # æå–å…³é”®å¥å­ï¼ˆåŒ…å«å…³é”®ä¿¡æ¯çš„å®Œæ•´å¥å­ï¼‰
        sentences = self._split_sentences(text)
        for sentence in sentences:
            if self._is_factual_sentence(sentence):
                facts.append(sentence.strip())
        
        return facts
    
    def _split_sentences(self, text: str) -> List[str]:
        """åˆ†å¥"""
        # ä½¿ç”¨æ ‡ç‚¹ç¬¦å·åˆ†å¥
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
        return [s.strip() for s in sentences if len(s.strip()) > 5]
    
    def _is_factual_sentence(self, sentence: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºäº‹å®æ€§å¥å­"""
        # åŒ…å«å…·ä½“ä¿¡æ¯çš„å¥å­æ›´å¯èƒ½æ˜¯äº‹å®
        factual_indicators = [
            r'\d+',  # åŒ…å«æ•°å­—
            r'[ã€Š""].*?[ã€‹""]',  # åŒ…å«å¼•ç”¨
            r'æ—¶é—´|æ—¥æœŸ|åœ°ç‚¹|ç”µè¯|é‚®ç®±',  # åŒ…å«å…³é”®ä¿¡æ¯è¯
            r'ä¸“é¡¹èµ›|ç«èµ›|å¤§èµ›|æ¯”èµ›',  # åŒ…å«ç«èµ›ç›¸å…³è¯
            r'è¦æ±‚|æ¡ä»¶|æ ‡å‡†|è§„å®š'  # åŒ…å«è§„åˆ™ç›¸å…³è¯
        ]
        
        for indicator in factual_indicators:
            if re.search(indicator, sentence):
                return True
        
        return False
    
    def _check_fact_support(self, answer_facts: List[str], 
                           context_facts: List[str]) -> Tuple[List[str], List[str]]:
        """æ£€æŸ¥äº‹å®æ”¯æŒåº¦"""
        supported_facts = []
        unsupported_facts = []
        
        for answer_fact in answer_facts:
            is_supported = False
            
            # 1. ç²¾ç¡®åŒ¹é…
            if answer_fact in context_facts:
                is_supported = True
            else:
                # 2. æ¨¡ç³ŠåŒ¹é…
                for context_fact in context_facts:
                    similarity = self._calculate_text_similarity(answer_fact, context_fact)
                    if similarity >= self.fact_similarity_threshold:
                        is_supported = True
                        break
                
                # 3. éƒ¨åˆ†åŒ¹é…ï¼ˆå¯¹äºå¤åˆäº‹å®ï¼‰
                if not is_supported:
                    is_supported = self._check_partial_support(answer_fact, context_facts)
            
            if is_supported:
                supported_facts.append(answer_fact)
            else:
                unsupported_facts.append(answer_fact)
        
        return supported_facts, unsupported_facts
    
    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
        # ä½¿ç”¨difflibè®¡ç®—åºåˆ—ç›¸ä¼¼åº¦
        similarity = difflib.SequenceMatcher(None, text1, text2).ratio()
        return similarity
    
    def _check_partial_support(self, fact: str, context_facts: List[str]) -> bool:
        """æ£€æŸ¥éƒ¨åˆ†æ”¯æŒï¼ˆå¯¹äºå¤åˆäº‹å®ï¼‰"""
        # å°†äº‹å®åˆ†è§£ä¸ºå…³é”®è¯
        fact_keywords = self._extract_keywords(fact)
        
        for context_fact in context_facts:
            context_keywords = self._extract_keywords(context_fact)
            
            # å¦‚æœå…³é”®è¯æœ‰è¶³å¤Ÿçš„é‡å ï¼Œè®¤ä¸ºæ˜¯éƒ¨åˆ†æ”¯æŒ
            overlap = set(fact_keywords).intersection(set(context_keywords))
            if len(overlap) >= len(fact_keywords) * 0.6:  # 60%çš„å…³é”®è¯é‡å 
                return True
        
        return False
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ä½¿ç”¨jiebaåˆ†è¯
        words = jieba.lcut(text)
        
        # è¿‡æ»¤åœç”¨è¯
        stopwords = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'éƒ½', 'ä¸€', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä¼š', 'ç€', 'çœ‹', 'å¥½', 'è¿™', 'é‚£'}
        keywords = [word for word in words if len(word) > 1 and word not in stopwords]
        
        return keywords
    
    def _check_missing_info(self, question: str, answer: str, context: str) -> List[str]:
        """æ£€æŸ¥ç¼ºå¤±ä¿¡æ¯"""
        missing_info = []
        
        # åˆ†æé—®é¢˜ç±»å‹ï¼Œæ£€æŸ¥æ˜¯å¦å›ç­”å®Œæ•´
        question_type = self._classify_question_type(question)
        
        if question_type == "æ—¶é—´æŸ¥è¯¢":
            # æ£€æŸ¥æ˜¯å¦æä¾›äº†æ—¶é—´ä¿¡æ¯
            if not re.search(r'\d{4}å¹´|\d{1,2}æœˆ|\d{1,2}æ—¥|æ—¶é—´', answer):
                if re.search(r'\d{4}å¹´|\d{1,2}æœˆ|\d{1,2}æ—¥|æ—¶é—´', context):
                    missing_info.append("æ—¶é—´ä¿¡æ¯")
        
        elif question_type == "ç»Ÿè®¡æŸ¥è¯¢":
            # æ£€æŸ¥æ˜¯å¦æä¾›äº†æ•°é‡ä¿¡æ¯
            if not re.search(r'\d+ä¸ª|\d+é¡¹|\d+', answer):
                if re.search(r'\d+ä¸ª|\d+é¡¹|\d+', context):
                    missing_info.append("æ•°é‡ç»Ÿè®¡")
        
        elif question_type == "è”ç³»æŸ¥è¯¢":
            # æ£€æŸ¥æ˜¯å¦æä¾›äº†è”ç³»æ–¹å¼
            contact_patterns = [r'\d{3,4}-?\d{7,8}', r'\w+@\w+\.\w+', r'QQ', r'å¾®ä¿¡']
            answer_has_contact = any(re.search(pattern, answer) for pattern in contact_patterns)
            context_has_contact = any(re.search(pattern, context) for pattern in contact_patterns)
            
            if not answer_has_contact and context_has_contact:
                missing_info.append("è”ç³»æ–¹å¼")
        
        return missing_info
    
    def _classify_question_type(self, question: str) -> str:
        """åˆ†ç±»é—®é¢˜ç±»å‹"""
        if re.search(r'ä»€ä¹ˆæ—¶å€™|ä½•æ—¶|æ—¶é—´|æ—¥æœŸ', question):
            return "æ—¶é—´æŸ¥è¯¢"
        elif re.search(r'å¤šå°‘|å‡ ä¸ª|æ•°é‡', question):
            return "ç»Ÿè®¡æŸ¥è¯¢"
        elif re.search(r'è”ç³»|ç”µè¯|é‚®ç®±', question):
            return "è”ç³»æŸ¥è¯¢"
        elif re.search(r'ä»€ä¹ˆæ˜¯|æ˜¯ä»€ä¹ˆ|å®šä¹‰', question):
            return "å®šä¹‰æŸ¥è¯¢"
        else:
            return "é€šç”¨æŸ¥è¯¢"
    
    def _calculate_comprehensive_confidence(self, rouge_score: float, bleu_score: float, 
                                         text_overlap_ratio: float, answer_facts: List[str], 
                                         supported_facts: List[str], unsupported_facts: List[str]) -> float:
        """
        è®¡ç®—ç»¼åˆç½®ä¿¡åº¦ï¼ˆç»“åˆé‡å åº¦å’Œäº‹å®æ”¯æŒåº¦ï¼‰
        
        Args:
            rouge_score: ROUGEåˆ†æ•°
            bleu_score: BLEUåˆ†æ•°
            text_overlap_ratio: æ–‡æœ¬é‡å åº¦
            answer_facts: ç­”æ¡ˆäº‹å®
            supported_facts: æ”¯æŒçš„äº‹å®
            unsupported_facts: ä¸æ”¯æŒçš„äº‹å®
            
        Returns:
            ç»¼åˆç½®ä¿¡åº¦
        """
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ—¥æœŸç±»ç­”æ¡ˆï¼ˆåŒ…å«æ˜ç¡®çš„æ—¥æœŸä¿¡æ¯ï¼‰
        answer_text = " ".join(answer_facts) if answer_facts else ""
        is_date_answer = self._is_date_answer(answer_text)
        
        # ğŸš€ ä¼˜åŒ–é‡å åº¦è®¡ç®—ï¼šç»™æ–‡æœ¬é‡å åº¦æ›´é«˜æƒé‡ï¼Œé™ä½BLEUæƒé‡
        # æ–‡æœ¬é‡å åº¦é€šå¸¸æ¯”BLEUæ›´å‡†ç¡®ï¼Œç‰¹åˆ«æ˜¯å¯¹ä¸­æ–‡
        weighted_overlap = (rouge_score * 0.3 + bleu_score * 0.2 + text_overlap_ratio * 0.5)
        
        # ğŸš€ é’ˆå¯¹æ—¥æœŸç±»ç­”æ¡ˆçš„ç‰¹æ®Šå¤„ç†
        if is_date_answer:
            # æ—¥æœŸç±»ç­”æ¡ˆï¼šå¤§å¹…æé«˜æ–‡æœ¬é‡å åº¦æƒé‡ï¼Œé™ä½äº‹å®æƒé‡
            if text_overlap_ratio >= 0.5:  # é™ä½é˜ˆå€¼
                overlap_score = weighted_overlap * 0.9  # æé«˜æƒé‡
                fact_weight = 0.1  # å¤§å¹…é™ä½äº‹å®æƒé‡
            else:
                overlap_score = weighted_overlap * 0.8
                fact_weight = 0.2
        else:
            # éæ—¥æœŸç±»ç­”æ¡ˆï¼šä½¿ç”¨åŸæœ‰é€»è¾‘
            if text_overlap_ratio >= 0.8:
                overlap_score = weighted_overlap * 0.85
                fact_weight = 0.15
            elif weighted_overlap >= 0.6:
                overlap_score = weighted_overlap * 0.8
                fact_weight = 0.2
            else:
                overlap_score = weighted_overlap * 0.65
                fact_weight = 0.35
        
        # äº‹å®æ”¯æŒåº¦å¾—åˆ†
        if answer_facts:
            fact_support_ratio = len(supported_facts) / len(answer_facts)
            fact_support_score = fact_support_ratio * fact_weight
        else:
            fact_support_score = fact_weight  # æ²¡æœ‰äº‹å®æ—¶ç»™äºˆæ»¡åˆ†
        
        # ç»¼åˆç½®ä¿¡åº¦
        base_confidence = overlap_score + fact_support_score
        
        # ğŸš€ é’ˆå¯¹æ—¥æœŸç±»ç­”æ¡ˆçš„æƒ©ç½šä¼˜åŒ–
        if is_date_answer:
            # æ—¥æœŸç±»ç­”æ¡ˆï¼šå¤§å¹…å‡å°‘æƒ©ç½š
            if text_overlap_ratio >= 0.5:
                unsupported_penalty = len(unsupported_facts) * 0.01  # æå°æƒ©ç½š
            else:
                unsupported_penalty = len(unsupported_facts) * 0.02
        else:
            # éæ—¥æœŸç±»ç­”æ¡ˆï¼šåŸæœ‰æƒ©ç½šé€»è¾‘
            if text_overlap_ratio >= 0.8:
                unsupported_penalty = len(unsupported_facts) * 0.02
            elif weighted_overlap >= 0.6:
                unsupported_penalty = len(unsupported_facts) * 0.03
            else:
                unsupported_penalty = len(unsupported_facts) * 0.05
            
        confidence = max(0.0, base_confidence - unsupported_penalty)
        
        # ğŸš€ ä¼˜åŒ–ï¼šå¯¹äºé«˜é‡å åº¦ç»™äºˆå¥–åŠ±
        if is_date_answer and text_overlap_ratio >= 0.5:
            confidence = min(1.0, confidence * 1.2)  # æ—¥æœŸç±»ç­”æ¡ˆ20%å¥–åŠ±
        elif text_overlap_ratio >= 0.8:
            confidence = min(1.0, confidence * 1.15)  # 15%å¥–åŠ±
        elif weighted_overlap >= 0.7:
            confidence = min(1.0, confidence * 1.1)   # 10%å¥–åŠ±
        
        return min(1.0, confidence)
    
    def _is_date_answer(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ—¥æœŸç±»ç­”æ¡ˆ"""
        import re
        # åŒ¹é…å¸¸è§çš„æ—¥æœŸæ ¼å¼
        date_patterns = [
            r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥',  # 2024å¹´4æœˆ15æ—¥
            r'\d{1,2}æœˆ\d{1,2}æ—¥',         # 4æœˆ15æ—¥
            r'\d{4}-\d{1,2}-\d{1,2}',      # 2024-04-15
            r'\d{1,2}/\d{1,2}/\d{4}',      # 04/15/2024
        ]
        
        for pattern in date_patterns:
            if re.search(pattern, text):
                return True
        return False
    
    def _build_validation_details(self, answer: str, context: str,
                                answer_facts: List[str], context_facts: List[str],
                                supported_facts: List[str], unsupported_facts: List[str],
                                rouge_score: float, bleu_score: float, text_overlap_ratio: float) -> Dict:
        """æ„å»ºéªŒè¯è¯¦æƒ…"""
        return {
            "answer_length": len(answer),
            "context_length": len(context),
            "total_answer_facts": len(answer_facts),
            "total_context_facts": len(context_facts),
            "supported_count": len(supported_facts),
            "unsupported_count": len(unsupported_facts),
            "validation_timestamp": datetime.now().isoformat(),
            "fact_examples": {
                "supported": supported_facts[:3],  # å‰3ä¸ªæ”¯æŒçš„äº‹å®
                "unsupported": unsupported_facts[:3]  # å‰3ä¸ªä¸æ”¯æŒçš„äº‹å®
            },
            "rouge_score": rouge_score,
            "bleu_score": bleu_score,
            "text_overlap_ratio": text_overlap_ratio,
            "overlap_thresholds": {
                "rouge_threshold": self.rouge_threshold,
                "bleu_threshold": self.bleu_threshold,
                "overlap_threshold": self.overlap_threshold
            }
        }
    
    def batch_validate(self, questions_answers_contexts: List[Tuple[str, str, str]]) -> List[ValidationResult]:
        """æ‰¹é‡éªŒè¯"""
        results = []
        for question, answer, context in questions_answers_contexts:
            result = self.validate_answer(question, answer, context)
            results.append(result)
        
        return results
    
    def get_validation_stats(self, results: List[ValidationResult]) -> Dict:
        """è·å–éªŒè¯ç»Ÿè®¡ä¿¡æ¯"""
        if not results:
            return {}
        
        hallucination_count = sum(1 for r in results if r.hallucination)
        avg_confidence = sum(r.confidence for r in results) / len(results)
        avg_fact_coverage = sum(r.fact_coverage for r in results) / len(results)
        
        return {
            "total_validations": len(results),
            "hallucination_count": hallucination_count,
            "hallucination_rate": hallucination_count / len(results),
            "avg_confidence": avg_confidence,
            "avg_fact_coverage": avg_fact_coverage,
            "high_confidence_count": sum(1 for r in results if r.confidence >= 0.8),
            "low_confidence_count": sum(1 for r in results if r.confidence < 0.5)
        }

class EnhancedAnswerValidator(AnswerValidator):
    """å¢å¼ºçš„ç­”æ¡ˆéªŒè¯å™¨"""
    
    def __init__(self, **kwargs):
        """åˆå§‹åŒ–å¢å¼ºéªŒè¯å™¨"""
        super().__init__(**kwargs)
        
        # æ·»åŠ æ›´å¤šéªŒè¯è§„åˆ™
        self.contradiction_patterns = [
            (r'ä¸æ˜¯', r'æ˜¯'),
            (r'æ²¡æœ‰', r'æœ‰'),
            (r'ä¸èƒ½', r'èƒ½'),
            (r'ä¸å…è®¸', r'å…è®¸'),
            (r'ç¦æ­¢', r'å¯ä»¥')
        ]
        
        # æ—¶é—´ä¸€è‡´æ€§æ£€æŸ¥
        self.time_patterns = [
            r'\d{4}å¹´',
            r'\d{1,2}æœˆ',
            r'\d{1,2}æ—¥'
        ]
    
    def validate_answer(self, question: str, answer: str, context: str) -> ValidationResult:
        """å¢å¼ºçš„ç­”æ¡ˆéªŒè¯"""
        # è°ƒç”¨åŸºç¡€éªŒè¯
        result = super().validate_answer(question, answer, context)
        
        # æ·»åŠ é¢å¤–éªŒè¯
        contradiction_check = self._check_contradictions(answer, context)
        consistency_check = self._check_time_consistency(answer, context)
        completeness_check = self._check_answer_completeness(question, answer)
        
        # æ›´æ–°éªŒè¯è¯¦æƒ…
        result.validation_details.update({
            "contradiction_detected": contradiction_check,
            "time_consistency": consistency_check,
            "answer_completeness": completeness_check
        })
        
        # å¦‚æœæ£€æµ‹åˆ°çŸ›ç›¾æˆ–ä¸ä¸€è‡´ï¼Œé™ä½ç½®ä¿¡åº¦
        if contradiction_check or not consistency_check or not completeness_check:
            result.confidence *= 0.8
            result.hallucination = result.confidence < self.hallucination_threshold or result.is_off_topic
        
        return result
    
    def _check_contradictions(self, answer: str, context: str) -> bool:
        """æ£€æŸ¥ç­”æ¡ˆä¸ä¸Šä¸‹æ–‡çš„çŸ›ç›¾"""
        for neg_pattern, pos_pattern in self.contradiction_patterns:
            # æ£€æŸ¥ç­”æ¡ˆä¸­çš„å¦å®šè¡¨è¿°æ˜¯å¦ä¸ä¸Šä¸‹æ–‡ä¸­çš„è‚¯å®šè¡¨è¿°çŸ›ç›¾
            if re.search(neg_pattern, answer) and re.search(pos_pattern, context):
                # è¿›ä¸€æ­¥æ£€æŸ¥æ˜¯å¦çœŸçš„çŸ›ç›¾ï¼ˆåŒä¸€ä¸»é¢˜ï¼‰
                answer_words = set(jieba.lcut(answer))
                context_words = set(jieba.lcut(context))
                overlap = answer_words.intersection(context_words)
                
                if len(overlap) > 3:  # å¦‚æœæœ‰è¶³å¤Ÿçš„è¯æ±‡é‡å ï¼Œå¯èƒ½å­˜åœ¨çŸ›ç›¾
                    return True
        
        return False
    
    def _check_time_consistency(self, answer: str, context: str) -> bool:
        """æ£€æŸ¥æ—¶é—´ä¸€è‡´æ€§"""
        answer_times = []
        context_times = []
        
        # æå–æ—¶é—´ä¿¡æ¯
        for pattern in self.time_patterns:
            answer_times.extend(re.findall(pattern, answer))
            context_times.extend(re.findall(pattern, context))
        
        # æ£€æŸ¥ç­”æ¡ˆä¸­çš„æ—¶é—´æ˜¯å¦åœ¨ä¸Šä¸‹æ–‡ä¸­å‡ºç°
        for answer_time in answer_times:
            if answer_time not in context_times:
                return False
        
        return True
    
    def _check_answer_completeness(self, question: str, answer: str) -> bool:
        """æ£€æŸ¥ç­”æ¡ˆå®Œæ•´æ€§"""
        # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦è¿‡çŸ­
        if len(answer) < 10:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«"ä¸çŸ¥é“"ã€"æ— æ³•å›ç­”"ç­‰è¯æ±‡
        uncertainty_phrases = ['ä¸çŸ¥é“', 'æ— æ³•å›ç­”', 'ä¸æ¸…æ¥š', 'æ²¡æœ‰ä¿¡æ¯', 'æ— æ³•ç¡®å®š']
        if any(phrase in answer for phrase in uncertainty_phrases):
            return False
        
        # æ£€æŸ¥é—®é¢˜çš„å…³é”®è¯æ˜¯å¦åœ¨ç­”æ¡ˆä¸­å‡ºç°
        question_keywords = self._extract_keywords(question)
        answer_keywords = self._extract_keywords(answer)
        
        overlap = set(question_keywords).intersection(set(answer_keywords))
        if len(overlap) < len(question_keywords) * 0.3:  # è‡³å°‘30%çš„å…³é”®è¯é‡å 
            return False
        
        return True 