"""
LangChainå¢å¼ºæ··åˆæ£€ç´¢å™¨
ç»“åˆBM25å’Œå‘é‡æ£€ç´¢ï¼Œé›†æˆé‡æ’åºåŠŸèƒ½ï¼Œæä¾›æ›´ç²¾å‡†çš„æœç´¢ç»“æœ
"""

from typing import List, Dict, Optional, Tuple, Any
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks import CallbackManagerForRetrieverRun

# ä¿®å¤å¯¼å…¥ - ä½¿ç”¨å…¼å®¹çš„å¯¼å…¥æ–¹å¼
try:
    from langchain_community.retrievers import BM25Retriever
except ImportError:
    try:
        from langchain.retrievers import BM25Retriever
    except ImportError:
        BM25Retriever = None

try:
    from langchain.retrievers import EnsembleRetriever
except ImportError:
    try:
        from langchain_community.retrievers import EnsembleRetriever  
    except ImportError:
        EnsembleRetriever = None

import numpy as np
from dataclasses import dataclass
from loguru import logger
import os

try:
    from .langchain_vectorstore import LangChainVectorStore
    from .bm25_retriever import BM25Retriever as EnhancedBM25Retriever
    from .reranker import Reranker
except ImportError:
    from langchain_vectorstore import LangChainVectorStore
    from bm25_retriever import BM25Retriever as EnhancedBM25Retriever
    from reranker import Reranker


@dataclass
class RetrievalResult:
    """æ£€ç´¢ç»“æœ"""
    document: Document
    score: float
    source: str  # 'bm25', 'vector', 'hybrid'
    rank: int


class SimpleBM25Retriever:
    """ç®€å•çš„BM25æ£€ç´¢å™¨ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
    
    def __init__(self, documents: List[Document], k: int = 5):
        self.documents = documents
        self.k = k
        
        # ç®€å•çš„å…³é”®è¯ç´¢å¼•
        self.keyword_index = {}
        self._build_index()
    
    def _build_index(self):
        """æ„å»ºå…³é”®è¯ç´¢å¼•"""
        import jieba
        
        for i, doc in enumerate(self.documents):
            words = jieba.lcut(doc.page_content.lower())
            for word in words:
                if len(word) > 1:  # å¿½ç•¥å•å­—ç¬¦
                    if word not in self.keyword_index:
                        self.keyword_index[word] = []
                    self.keyword_index[word].append(i)
    
    def get_relevant_documents(self, query: str) -> List[Document]:
        """è·å–ç›¸å…³æ–‡æ¡£"""
        import jieba
        
        query_words = jieba.lcut(query.lower())
        doc_scores = {}
        
        for word in query_words:
            if word in self.keyword_index:
                for doc_idx in self.keyword_index[word]:
                    if doc_idx not in doc_scores:
                        doc_scores[doc_idx] = 0
                    doc_scores[doc_idx] += 1
        
        # æŒ‰åˆ†æ•°æ’åº
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)
        
        # è¿”å›top-kæ–‡æ¡£
        results = []
        for doc_idx, score in sorted_docs[:self.k]:
            results.append(self.documents[doc_idx])
        
        return results


class LangChainHybridRetriever(BaseRetriever):
    """åŸºäºLangChainçš„æ··åˆæ£€ç´¢å™¨"""
    
    # Pydanticå­—æ®µå®šä¹‰
    vectorstore: LangChainVectorStore
    bm25_weight: float = 0.5
    vector_weight: float = 0.5
    k: int = 5
    bm25_retriever: Optional[Any] = None
    enhanced_bm25: Optional[Any] = None
    reranker: Optional[Any] = None
    
    class Config:
        arbitrary_types_allowed = True
    
    def __init__(self, 
                 vectorstore: LangChainVectorStore,
                 documents: List[Document] = None,
                 bm25_weight: float = 0.5,
                 vector_weight: float = 0.5,
                 k: int = 5,
                 enable_reranking: bool = True):
        """
        åˆå§‹åŒ–å¢å¼ºæ··åˆæ£€ç´¢å™¨
        
        Args:
            vectorstore: LangChainå‘é‡å­˜å‚¨
            documents: æ–‡æ¡£åˆ—è¡¨ï¼ˆç”¨äºBM25ï¼‰
            bm25_weight: BM25æƒé‡
            vector_weight: å‘é‡æ£€ç´¢æƒé‡
            k: è¿”å›ç»“æœæ•°é‡
            enable_reranking: æ˜¯å¦å¯ç”¨é‡æ’åº
        """
        super().__init__(
            vectorstore=vectorstore,
            bm25_weight=bm25_weight,
            vector_weight=vector_weight,
            k=k
        )
        
        # åˆå§‹åŒ–å¢å¼ºBM25æ£€ç´¢å™¨
        self.enhanced_bm25 = None
        if documents:
            try:
                # è½¬æ¢LangChainæ–‡æ¡£æ ¼å¼ä¸ºæˆ‘ä»¬çš„æ ¼å¼
                doc_data = []
                for doc in documents:
                    doc_data.append({
                        'content': doc.page_content,
                        'metadata': doc.metadata,
                        'source': doc.metadata.get('source', 'unknown')
                    })
                
                self.enhanced_bm25 = EnhancedBM25Retriever()
                self.enhanced_bm25.add_documents(doc_data)
                logger.info("å¢å¼ºBM25æ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"å¢å¼ºBM25æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–æ ‡å‡†BM25ä½œä¸ºé™çº§æ–¹æ¡ˆ
        if documents and BM25Retriever is not None:
            try:
                self.bm25_retriever = BM25Retriever.from_documents(documents)
                if hasattr(self.bm25_retriever, 'k'):
                    self.bm25_retriever.k = k
                logger.info("æ ‡å‡†BM25æ£€ç´¢å™¨ä½œä¸ºé™çº§æ–¹æ¡ˆ")
            except Exception as e:
                logger.warning(f"æ ‡å‡†BM25æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.bm25_retriever = SimpleBM25Retriever(documents, k)
        elif documents:
            self.bm25_retriever = SimpleBM25Retriever(documents, k)
        else:
            self.bm25_retriever = None
            
        # åˆå§‹åŒ–é‡æ’åºå™¨
        self.reranker = None
        if enable_reranking:
            try:
                self.reranker = Reranker()
                logger.info("é‡æ’åºå™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"é‡æ’åºå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                
        logger.info(f"å¢å¼ºæ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆï¼ŒBM25æƒé‡: {bm25_weight}, å‘é‡æƒé‡: {vector_weight}, é‡æ’åº: {enable_reranking}")
    
    def get_relevant_documents(self, query: str) -> List[Document]:
        """
        æ™ºèƒ½æ··åˆæ£€ç´¢ï¼šæŸ¥è¯¢ä¼˜åŒ– â†’ ç­–ç•¥é€‰æ‹© â†’ å¤šé˜¶æ®µæ£€ç´¢ â†’ ç«èµ›è¿‡æ»¤
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            æ’åºåçš„ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        try:
            try:
                from config import Config
            except ImportError:
                import sys
                import os
                sys.path.append(os.path.dirname(os.path.dirname(__file__)))
                from config import Config
            
            # === 1. æŸ¥è¯¢ä¼˜åŒ–å’Œç­–ç•¥é€‰æ‹© ===
            try:
                try:
                    from query_enhancer import get_enhanced_query_optimizer
                except ImportError:
                    from .query_enhancer import get_enhanced_query_optimizer
                optimizer = get_enhanced_query_optimizer()
                optimized_query, strategy = optimizer.optimize_query_for_retrieval(query)
                logger.info(f"ğŸ” æŸ¥è¯¢ä¼˜åŒ–: '{query}' -> '{optimized_query}'")
                logger.info(f"ğŸ¯ æ£€ç´¢ç­–ç•¥: {strategy}")
            except Exception as e:
                logger.warning(f"æŸ¥è¯¢ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢: {e}")
                optimized_query = query
                strategy = {
                    "question_type": "basic",
                    "competition_filter": None,
                    "alpha": 0.5,
                    "vector_k": 20,
                    "bm25_k": 30
                }
            
            # === 2. åŠ¨æ€è°ƒæ•´æ£€ç´¢å‚æ•° ===
            # æ ¹æ®ç­–ç•¥è°ƒæ•´æƒé‡
            original_vector_weight = self.vector_weight
            original_bm25_weight = self.bm25_weight
            
            alpha = strategy.get("alpha", 0.5)
            self.vector_weight = alpha
            self.bm25_weight = 1.0 - alpha
            
            # è·å–å¤šé˜¶æ®µæ£€ç´¢é…ç½®
            stages = getattr(Config, 'RETRIEVAL_STAGES', {})
            enable_multi_stage = stages.get('enable_multi_stage', True)
            
            # æ ¹æ®ç­–ç•¥è°ƒæ•´æ£€ç´¢æ•°é‡
            if strategy.get("question_type") == "competition":
                stages = stages.copy()  # é¿å…ä¿®æ”¹åŸé…ç½®
                stages["stage1_vector_k"] = strategy.get("vector_k", 15)
                stages["stage1_bm25_k"] = strategy.get("bm25_k", 35)
                logger.info(f"ğŸ† ç«èµ›æ¨¡å¼æ£€ç´¢: å‘é‡{stages['stage1_vector_k']}, BM25{stages['stage1_bm25_k']}")
            
            # === 3. æ‰§è¡Œæ£€ç´¢ ===
            try:
                if enable_multi_stage:
                    results = self._multi_stage_retrieval_with_filter(optimized_query, stages, strategy)
                else:
                    results = self._traditional_retrieval_with_filter(optimized_query, strategy)
            finally:
                # æ¢å¤åŸå§‹æƒé‡
                self.vector_weight = original_vector_weight
                self.bm25_weight = original_bm25_weight
            
            return results
                
        except Exception as e:
            logger.error(f"æ£€ç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # é™çº§åˆ°åŸºç¡€å‘é‡æ£€ç´¢
            if self.vectorstore:
                logger.info("ğŸ”„ é™çº§åˆ°åŸºç¡€å‘é‡æ£€ç´¢")
                return self.vectorstore.similarity_search(query, k=self.k)
            else:
                return []
    
    def _multi_stage_retrieval_with_filter(self, query: str, stages: Dict, strategy: Dict) -> List[Document]:
        """å¸¦ç«èµ›è¿‡æ»¤çš„å¤šé˜¶æ®µæ£€ç´¢å®ç°"""
        stage1_vector_k = stages.get('stage1_vector_k', 50)
        stage1_bm25_k = stages.get('stage1_bm25_k', 50)
        stage2_candidate_k = stages.get('stage2_candidate_k', 80)
        final_k = stages.get('final_k', 10)
        
        logger.info(f"ğŸ” === å¼€å§‹æ™ºèƒ½å¤šé˜¶æ®µæ£€ç´¢ ===")
        logger.info(f"ğŸ“ æŸ¥è¯¢: {query}")
        logger.info(f"ğŸ¯ æ£€ç´¢é…ç½®: å‘é‡{stage1_vector_k} + BM25{stage1_bm25_k} â†’ å€™é€‰{stage2_candidate_k} â†’ æœ€ç»ˆ{final_k}")
        
        competition_filter = strategy.get("competition_filter")
        if competition_filter:
            logger.info(f"ğŸ† ç«èµ›è¿‡æ»¤: {competition_filter}")
            
        # æ‰§è¡ŒåŸæœ‰çš„å¤šé˜¶æ®µæ£€ç´¢é€»è¾‘
        results = self._multi_stage_retrieval_core(query, stages)
        
        # åº”ç”¨ç«èµ›è¿‡æ»¤å’ŒåŠ æƒ
        if competition_filter:
            results = self._apply_competition_filter(results, competition_filter, strategy)
        
        return results
    
    def _traditional_retrieval_with_filter(self, query: str, strategy: Dict) -> List[Document]:
        """å¸¦ç«èµ›è¿‡æ»¤çš„ä¼ ç»Ÿæ£€ç´¢å®ç°"""
        logger.info(f"ğŸ” === ä½¿ç”¨æ™ºèƒ½ä¼ ç»Ÿæ£€ç´¢æ–¹æ³• ===")
        logger.info(f"ğŸ“ æŸ¥è¯¢: {query}")
        
        competition_filter = strategy.get("competition_filter")
        if competition_filter:
            logger.info(f"ğŸ† ç«èµ›è¿‡æ»¤: {competition_filter}")
            
        # æ‰§è¡ŒåŸæœ‰çš„ä¼ ç»Ÿæ£€ç´¢é€»è¾‘
        results = self._traditional_retrieval_core(query)
        
        # åº”ç”¨ç«èµ›è¿‡æ»¤å’ŒåŠ æƒ
        if competition_filter:
            results = self._apply_competition_filter(results, competition_filter, strategy)
        
        return results

    def _multi_stage_retrieval_core(self, query: str, stages: Dict) -> List[Document]:
        """å¤šé˜¶æ®µæ£€ç´¢æ ¸å¿ƒå®ç°ï¼ˆåŸ_multi_stage_retrievalï¼‰"""
        stage1_vector_k = stages.get('stage1_vector_k', 50)
        stage1_bm25_k = stages.get('stage1_bm25_k', 50)
        stage2_candidate_k = stages.get('stage2_candidate_k', 80)
        final_k = stages.get('final_k', 10)
        
        # === ç¬¬ä¸€é˜¶æ®µï¼šå¹¿æ³›æ£€ç´¢ ===
        logger.info("ğŸš€ ç¬¬ä¸€é˜¶æ®µï¼šå¹¿æ³›æ£€ç´¢...")
        
        # 1.1 å‘é‡æ£€ç´¢ - è·å–æ›´å¤šå€™é€‰
        logger.info(f"ğŸ§  å‘é‡æ£€ç´¢ï¼ˆç›®æ ‡ï¼š{stage1_vector_k}ä¸ªï¼‰...")
        vector_docs = []
        vector_scores = {}
        if self.vectorstore:
            try:
                docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=stage1_vector_k)
                for doc, score in docs_with_scores:
                    vector_docs.append(doc)
                    vector_scores[doc.page_content] = 1.0 / (1.0 + score)
                logger.info(f"ğŸ“„ å‘é‡æ£€ç´¢è¿”å› {len(vector_docs)} ä¸ªæ–‡æ¡£")
            except Exception as e:
                logger.warning(f"å‘é‡æ£€ç´¢å¤±è´¥: {e}")
                vector_docs = self.vectorstore.similarity_search(query, k=stage1_vector_k)
                for i, doc in enumerate(vector_docs):
                    vector_scores[doc.page_content] = 1.0 / (1.0 + i)
        else:
            logger.warning("âš ï¸ å‘é‡å­˜å‚¨ä¸å¯ç”¨")

        # 1.2 BM25æ£€ç´¢ - è·å–æ›´å¤šå€™é€‰
        logger.info(f"ğŸ“Š BM25æ£€ç´¢ï¼ˆç›®æ ‡ï¼š{stage1_bm25_k}ä¸ªï¼‰...")
        bm25_docs = []
        bm25_scores = {}
        if self.enhanced_bm25:
            try:
                results = self.enhanced_bm25.search(query, k=stage1_bm25_k)
                for result, score in results:
                    doc = Document(
                        page_content=result['content'],
                        metadata=result['metadata']
                    )
                    doc.metadata['source_type'] = 'bm25'
                    bm25_docs.append(doc)
                    bm25_scores[doc.page_content] = score
                logger.info(f"ğŸ“Š å¢å¼ºBM25è¿”å› {len(bm25_docs)} ä¸ªæ–‡æ¡£")
            except Exception as e:
                logger.warning(f"å¢å¼ºBM25æ£€ç´¢å¤±è´¥: {e}")
        elif self.bm25_retriever:
            try:
                if hasattr(self.bm25_retriever, 'get_relevant_documents'):
                    bm25_docs = self.bm25_retriever.get_relevant_documents(query)[:stage1_bm25_k]
                else:
                    bm25_docs = self.bm25_retriever.invoke(query)[:stage1_bm25_k]
                for i, doc in enumerate(bm25_docs):
                    doc.metadata['source_type'] = 'bm25'
                    bm25_scores[doc.page_content] = 1.0 / (1.0 + i)
                logger.info(f"ğŸ“Š æ ‡å‡†BM25è¿”å› {len(bm25_docs)} ä¸ªæ–‡æ¡£")
            except Exception as e:
                logger.warning(f"æ ‡å‡†BM25æ£€ç´¢å¤±è´¥: {e}")
        else:
            logger.warning("âš ï¸ BM25æ£€ç´¢å™¨ä¸å¯ç”¨")

        # === ç¬¬äºŒé˜¶æ®µï¼šåˆå¹¶å»é‡ ===
        logger.info("ğŸ”„ ç¬¬äºŒé˜¶æ®µï¼šåˆå¹¶å»é‡...")
        all_candidates = self._merge_candidates(vector_docs, bm25_docs, vector_scores, bm25_scores)
        
        # é™åˆ¶å€™é€‰æ•°é‡
        candidates = all_candidates[:stage2_candidate_k]
        logger.info(f"ğŸ“‹ åˆå¹¶åå€™é€‰æ–‡æ¡£: {len(candidates)} ä¸ªï¼ˆç›®æ ‡: {stage2_candidate_k}ï¼‰")
        
        # æ˜¾ç¤ºå€™é€‰æ–‡æ¡£æ¥æºåˆ†å¸ƒ
        candidate_sources = [os.path.basename(doc.metadata.get('source', 'unknown')) for doc in candidates]
        from collections import Counter
        source_counter = Counter(candidate_sources)
        logger.info("ğŸ“Š å€™é€‰æ–‡æ¡£æ¥æºåˆ†å¸ƒ:")
        for source, count in source_counter.most_common():
            logger.info(f"  ğŸ“„ {source}: {count} ä¸ªç‰‡æ®µ")

        # === ç¬¬ä¸‰é˜¶æ®µï¼šé‡æ’åºé€‰æ‹© ===
        logger.info("ğŸ¯ ç¬¬ä¸‰é˜¶æ®µï¼šé‡æ’åºé€‰æ‹©...")
        if self.reranker and candidates:
            try:
                logger.info(f"ğŸ”§ ä½¿ç”¨é‡æ’åºå™¨ä» {len(candidates)} ä¸ªå€™é€‰ä¸­é€‰æ‹© {final_k} ä¸ª")
                reranked_docs = self.reranker.rerank(query, candidates, top_k=final_k)
                logger.info(f"âœ… é‡æ’åºå®Œæˆï¼Œè¿”å› {len(reranked_docs)} ä¸ªæ–‡æ¡£")
                
                # æ˜¾ç¤ºæœ€ç»ˆç»“æœç»Ÿè®¡
                final_sources = [os.path.basename(doc.metadata.get('source', 'unknown')) for doc in reranked_docs]
                final_counter = Counter(final_sources)
                logger.info("ğŸ“Š æœ€ç»ˆç»“æœæ¥æºåˆ†å¸ƒ:")
                for source, count in final_counter.most_common():
                    logger.info(f"  ğŸ“„ {source}: {count} ä¸ªç‰‡æ®µ")
                
                return reranked_docs
            except Exception as e:
                logger.warning(f"é‡æ’åºå¤±è´¥ï¼Œä½¿ç”¨å€™é€‰æ’åº: {e}")
                return candidates[:final_k]
        else:
            logger.info("â­ï¸ è·³è¿‡é‡æ’åºï¼Œç›´æ¥è¿”å›å€™é€‰æ–‡æ¡£")
            return candidates[:final_k]

    def _merge_candidates(self, vector_docs: List[Document], bm25_docs: List[Document], 
                         vector_scores: Dict, bm25_scores: Dict) -> List[Document]:
        """åˆå¹¶å€™é€‰æ–‡æ¡£å¹¶è®¡ç®—ç»¼åˆåˆ†æ•°"""
        all_docs = {}
        
        # å¤„ç†å‘é‡æ£€ç´¢ç»“æœ
        for doc in vector_docs:
            content = doc.page_content
            source = doc.metadata.get('source', 'unknown')
            unique_key = f"{source}_{content[:100]}"
            
            vector_score = vector_scores.get(content, 0.0)
            
            doc.metadata['source_type'] = 'vector'
            doc.metadata['vector_score'] = vector_score
            doc.metadata['bm25_score'] = 0.0
            doc.metadata['hybrid_score'] = self.vector_weight * vector_score
            
            all_docs[unique_key] = {
                'document': doc,
                'score': self.vector_weight * vector_score,
                'sources': {'vector'}
            }
        
        # å¤„ç†BM25æ£€ç´¢ç»“æœ
        for doc in bm25_docs:
            content = doc.page_content
            source = doc.metadata.get('source', 'unknown')
            unique_key = f"{source}_{content[:100]}"
            
            bm25_score = bm25_scores.get(content, 0.0)
            
            if unique_key in all_docs:
                # æ–‡æ¡£å·²å­˜åœ¨ï¼Œæ›´æ–°åˆ†æ•°
                existing_doc = all_docs[unique_key]['document']
                existing_doc.metadata['source_type'] = 'hybrid'
                existing_doc.metadata['bm25_score'] = bm25_score
                existing_doc.metadata['hybrid_score'] += self.bm25_weight * bm25_score
                all_docs[unique_key]['score'] += self.bm25_weight * bm25_score
                all_docs[unique_key]['sources'].add('bm25')
            else:
                # æ–°æ–‡æ¡£
                doc.metadata['source_type'] = 'bm25'
                doc.metadata['vector_score'] = 0.0
                doc.metadata['bm25_score'] = bm25_score
                doc.metadata['hybrid_score'] = self.bm25_weight * bm25_score
                
                all_docs[unique_key] = {
                    'document': doc,
                    'score': self.bm25_weight * bm25_score,
                    'sources': {'bm25'}
                }
        
        # æŒ‰ç»¼åˆåˆ†æ•°æ’åº
        sorted_results = sorted(all_docs.values(), key=lambda x: x['score'], reverse=True)
        return [result['document'] for result in sorted_results]
    
    def _traditional_retrieval(self, query: str) -> List[Document]:
        """ä¼ ç»Ÿæ£€ç´¢æ–¹æ³•ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰"""
        logger.info(f"ğŸ” === ä½¿ç”¨ä¼ ç»Ÿæ£€ç´¢æ–¹æ³• ===")
        logger.info(f"ğŸ“ æŸ¥è¯¢: {query}")
        
        # 1. å‘é‡æ£€ç´¢
        logger.info("ğŸ§  å¼€å§‹å‘é‡æ£€ç´¢...")
        vector_docs = []
        if self.vectorstore:
            vector_docs = self.vectorstore.similarity_search_with_score(query, k=self.k)
            logger.info(f"ğŸ“„ å‘é‡æ£€ç´¢è¿”å› {len(vector_docs)} ä¸ªæ–‡æ¡£")
        else:
            logger.warning("âš ï¸ å‘é‡å­˜å‚¨ä¸å¯ç”¨")

        # 2. BM25æ£€ç´¢
        logger.info("ğŸ“Š å¼€å§‹BM25æ£€ç´¢...")
        bm25_docs = []
        if self.enhanced_bm25:
            try:
                results = self.enhanced_bm25.search(query, k=self.k)
                for result, score in results:
                    doc = Document(
                        page_content=result['content'],
                        metadata=result['metadata']
                    )
                    doc.metadata['source_type'] = 'bm25'
                    bm25_docs.append(doc)
                logger.info(f"ğŸ“Š å¢å¼ºBM25è¿”å› {len(bm25_docs)} ä¸ªæ–‡æ¡£")
            except Exception as e:
                logger.warning(f"å¢å¼ºBM25æ£€ç´¢å¤±è´¥: {e}")
        elif self.bm25_retriever:
            try:
                bm25_docs = self.bm25_retriever.get_relevant_documents(query)[:self.k]
                for doc in bm25_docs:
                    doc.metadata['source_type'] = 'bm25'
                logger.info(f"ğŸ“Š æ ‡å‡†BM25è¿”å› {len(bm25_docs)} ä¸ªæ–‡æ¡£")
            except Exception as e:
                logger.warning(f"BM25æ£€ç´¢å¤±è´¥: {e}")
        else:
            logger.warning("âš ï¸ BM25æ£€ç´¢å™¨ä¸å¯ç”¨")

        # 3. åˆå¹¶å’Œé‡æ’åº
        logger.info("ğŸ”— å¼€å§‹åˆå¹¶æ£€ç´¢ç»“æœ...")
        
        # æå–å‘é‡æ–‡æ¡£
        vector_only_docs = [doc for doc, score in vector_docs] if vector_docs else []
        for doc in vector_only_docs:
            doc.metadata['source_type'] = 'vector'
        
        # åˆå¹¶æ‰€æœ‰æ–‡æ¡£
        all_docs = vector_only_docs + bm25_docs
        
        # 4. é‡æ’åºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.reranker and all_docs:
            try:
                logger.info("ğŸ¯ å¼€å§‹é‡æ’åº...")
                reranked_docs = self.reranker.rerank(query, all_docs, top_k=self.k)
                logger.info(f"âœ… é‡æ’åºå®Œæˆï¼Œè¿”å› {len(reranked_docs)} ä¸ªæ–‡æ¡£")
                return reranked_docs
            except Exception as e:
                logger.warning(f"é‡æ’åºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ’åº: {e}")
        
        # 5. è¿”å›ç»“æœ
        return all_docs[:self.k]
    
    def _merge_results_enhanced(self, vector_docs: List[Document], bm25_docs: List[Document], 
                              vector_scores: Dict, bm25_scores: Dict, query: str) -> List[Document]:
        """
        å¢å¼ºçš„ç»“æœåˆå¹¶æ–¹æ³•ï¼Œä½¿ç”¨çœŸå®åˆ†æ•°è€Œä¸æ˜¯æ’åºä½ç½®ï¼Œå¢å¼ºå»é‡æœºåˆ¶
        
        Args:
            vector_docs: å‘é‡æ£€ç´¢ç»“æœ
            bm25_docs: BM25æ£€ç´¢ç»“æœ
            vector_scores: å‘é‡æ£€ç´¢åˆ†æ•°
            bm25_scores: BM25æ£€ç´¢åˆ†æ•°
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            åˆå¹¶åçš„æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # åˆå¹¶è®¡ç®—æ··åˆåˆ†æ•° - ä½¿ç”¨æ¥æº+å†…å®¹ä½œä¸ºå”¯ä¸€é”®
            all_docs = {}
            
            # å¤„ç†å‘é‡æ£€ç´¢ç»“æœ
            for doc in vector_docs:
                content = doc.page_content
                source = doc.metadata.get('source', 'unknown')
                
                # ä½¿ç”¨æ¥æº+å†…å®¹ç‰‡æ®µä½œä¸ºå”¯ä¸€é”®ï¼Œé¿å…é‡å¤æ–‡æ¡£
                unique_key = f"{source}_{content[:100]}"
                
                score = vector_scores.get(content, 0) * self.vector_weight
                if unique_key in all_docs:
                    all_docs[unique_key]['score'] += score
                    all_docs[unique_key]['sources'].add('vector')
                else:
                    all_docs[unique_key] = {
                        'document': doc,
                        'score': score,
                        'sources': {'vector'},
                        'source': source
                    }
            
            # å¤„ç†BM25æ£€ç´¢ç»“æœ
            for doc in bm25_docs:
                content = doc.page_content
                source = doc.metadata.get('source', 'unknown')
                
                # ä½¿ç”¨æ¥æº+å†…å®¹ç‰‡æ®µä½œä¸ºå”¯ä¸€é”®ï¼Œé¿å…é‡å¤æ–‡æ¡£
                unique_key = f"{source}_{content[:100]}"
                
                score = bm25_scores.get(content, 0) * self.bm25_weight
                if unique_key in all_docs:
                    all_docs[unique_key]['score'] += score
                    all_docs[unique_key]['sources'].add('bm25')
                else:
                    all_docs[unique_key] = {
                        'document': doc,
                        'score': score,
                        'sources': {'bm25'},
                        'source': source
                    }
            
            # å¢å¼ºæ’åºï¼šå¯¹äºå®šä¹‰æ€§æŸ¥è¯¢ç»™äºˆç‰¹æ®Šæƒé‡
            query_lower = query.lower()
            is_definition_query = any(word in query_lower for word in ['ä»€ä¹ˆ', 'åŸºæœ¬è¦æ±‚', 'ä»»åŠ¡', 'è¦æ±‚'])
            
            for key, doc_info in all_docs.items():
                content_lower = doc_info['document'].page_content.lower()
                
                # å®šä¹‰åŒ¹é…å¥–åŠ±
                if is_definition_query:
                    definition_bonus = 0.0
                    
                    # æ£€æŸ¥ä»»åŠ¡å®šä¹‰æ ‡è¯†ç¬¦
                    definition_indicators = ['ä»»åŠ¡ä¸€', 'ä»»åŠ¡äºŒ', 'ä»»åŠ¡ä¸‰', 'ä»»åŠ¡å››', 'ä»»åŠ¡äº”', 'åŸºæœ¬è¦æ±‚', 'ä»»åŠ¡è¦æ±‚', 'ä»»åŠ¡æƒ…å¢ƒ']
                    for indicator in definition_indicators:
                        if indicator in content_lower:
                            definition_bonus += 0.2
                    
                    # ç‰¹å®šå…³é”®è¯åŒ¹é…å¥–åŠ±
                    if 'äº¤é€šä¿¡å·ç¯' in query_lower and 'äº¤é€šä¿¡å·ç¯' in content_lower:
                        definition_bonus += 0.5
                    elif 'ä¿¡å·ç¯' in query_lower and 'ä¿¡å·ç¯' in content_lower:
                        definition_bonus += 0.3
                    
                    # åº”ç”¨å®šä¹‰å¥–åŠ±
                    doc_info['score'] *= (1 + definition_bonus)
            
            # æŒ‰åˆ†æ•°æ’åº
            sorted_results = sorted(all_docs.values(), key=lambda x: x['score'], reverse=True)
            
            # è¿”å›æ–‡æ¡£åˆ—è¡¨ï¼Œç¡®ä¿å»é‡
            return [result['document'] for result in sorted_results[:self.k * 2]]
            
        except Exception as e:
            logger.error(f"ç»“æœåˆå¹¶å¤±è´¥: {e}")
            # é™çº§æ–¹æ¡ˆï¼šç®€å•æ‹¼æ¥å¹¶å»é‡
            seen_sources = set()
            unique_docs = []
            for doc in (vector_docs + bm25_docs):
                source = doc.metadata.get('source', 'unknown')
                content_key = f"{source}_{doc.page_content[:100]}"
                if content_key not in seen_sources:
                    seen_sources.add(content_key)
                    unique_docs.append(doc)
            return unique_docs[:self.k * 2]

    def _merge_results(self, vector_docs: List[Document], bm25_docs: List[Document], query: str) -> List[Document]:
        """
        åˆå¹¶BM25å’Œå‘é‡æ£€ç´¢ç»“æœ
        
        Args:
            vector_docs: å‘é‡æ£€ç´¢ç»“æœ
            bm25_docs: BM25æ£€ç´¢ç»“æœ
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            åˆå¹¶åçš„æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # è®¡ç®—å‘é‡ç›¸ä¼¼åº¦åˆ†æ•°
            vector_scores = {}
            if self.vectorstore.get_vectorstore():
                try:
                    docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=self.k)
                    for doc, score in docs_with_scores:
                        vector_scores[doc.page_content] = 1.0 / (1.0 + score)  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
                except Exception as e:
                    logger.warning(f"è·å–å‘é‡åˆ†æ•°å¤±è´¥: {e}")
                    # ä½¿ç”¨æ’åºä½ç½®ä½œä¸ºåˆ†æ•°
                    for i, doc in enumerate(vector_docs):
                        vector_scores[doc.page_content] = 1.0 / (1.0 + i)
            
            # è®¡ç®—BM25åˆ†æ•°ï¼ˆåŸºäºæ’åºä½ç½®ï¼‰
            bm25_scores = {}
            for i, doc in enumerate(bm25_docs):
                bm25_scores[doc.page_content] = 1.0 / (1.0 + i)  # åŸºäºæ’åºä½ç½®çš„åˆ†æ•°
            
            # åˆå¹¶è®¡ç®—æ··åˆåˆ†æ•°
            all_docs = {}
            
            # å¤„ç†å‘é‡æ£€ç´¢ç»“æœ
            for doc in vector_docs:
                content = doc.page_content
                vector_score = vector_scores.get(content, 0.0)
                bm25_score = bm25_scores.get(content, 0.0)
                hybrid_score = self.vector_weight * vector_score + self.bm25_weight * bm25_score
                
                if content not in all_docs or hybrid_score > all_docs[content]['score']:
                    all_docs[content] = {
                        'document': doc,
                        'score': hybrid_score,
                        'vector_score': vector_score,
                        'bm25_score': bm25_score
                    }
            
            # å¤„ç†BM25æ£€ç´¢ç»“æœ
            for doc in bm25_docs:
                content = doc.page_content
                if content not in all_docs:
                    vector_score = vector_scores.get(content, 0.0)
                    bm25_score = bm25_scores.get(content, 0.0)
                    hybrid_score = self.vector_weight * vector_score + self.bm25_weight * bm25_score
                    
                    all_docs[content] = {
                        'document': doc,
                        'score': hybrid_score,
                        'vector_score': vector_score,
                        'bm25_score': bm25_score
                    }
            
            # æŒ‰åˆ†æ•°æ’åº
            sorted_results = sorted(all_docs.values(), key=lambda x: x['score'], reverse=True)
            
            # è¿”å›top-kç»“æœ
            return [result['document'] for result in sorted_results[:self.k]]
            
        except Exception as e:
            logger.error(f"ç»“æœåˆå¹¶å¤±è´¥: {e}")
            # é™çº§å¤„ç†ï¼šè¿”å›å‘é‡æ£€ç´¢ç»“æœ
            return vector_docs[:self.k] if vector_docs else bm25_docs[:self.k]
    
    def get_detailed_results(self, query: str) -> List[RetrievalResult]:
        """
        è·å–è¯¦ç»†çš„æ£€ç´¢ç»“æœ
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            è¯¦ç»†æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        try:
            results = []
            
            # å‘é‡æ£€ç´¢
            if self.vectorstore.get_vectorstore():
                try:
                    docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=self.k)
                    for i, (doc, score) in enumerate(docs_with_scores):
                        results.append(RetrievalResult(
                            document=doc,
                            score=1.0 / (1.0 + score),
                            source='vector',
                            rank=i + 1
                        ))
                except Exception as e:
                    logger.warning(f"å‘é‡æ£€ç´¢è¯¦ç»†ç»“æœè·å–å¤±è´¥: {e}")
                    # ä½¿ç”¨åŸºæœ¬å‘é‡æ£€ç´¢
                    vector_docs = self.vectorstore.similarity_search(query, k=self.k)
                    for i, doc in enumerate(vector_docs):
                        results.append(RetrievalResult(
                            document=doc,
                            score=1.0 / (1.0 + i),
                            source='vector',
                            rank=i + 1
                        ))
            
            # BM25æ£€ç´¢
            if self.bm25_retriever:
                bm25_docs = self.bm25_retriever.get_relevant_documents(query)
                for i, doc in enumerate(bm25_docs):
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = next((r for r in results if r.document.page_content == doc.page_content), None)
                    if existing:
                        existing.source = 'hybrid'
                    else:
                        results.append(RetrievalResult(
                            document=doc,
                            score=1.0 / (1.0 + i),
                            source='bm25',
                            rank=i + 1
                        ))
            
            # æŒ‰åˆ†æ•°æ’åº
            results.sort(key=lambda x: x.score, reverse=True)
            
            # æ›´æ–°æ’å
            for i, result in enumerate(results[:self.k]):
                result.rank = i + 1
            
            return results[:self.k]
            
        except Exception as e:
            logger.error(f"è¯¦ç»†æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def update_weights(self, bm25_weight: float, vector_weight: float):
        """
        æ›´æ–°æ£€ç´¢æƒé‡
        
        Args:
            bm25_weight: BM25æƒé‡
            vector_weight: å‘é‡æ£€ç´¢æƒé‡
        """
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight
        logger.info(f"æ£€ç´¢æƒé‡å·²æ›´æ–°ï¼ŒBM25: {bm25_weight}, å‘é‡: {vector_weight}")
    
    def add_documents(self, documents: List[Document]):
        """
        æ·»åŠ æ–‡æ¡£åˆ°æ£€ç´¢å™¨
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # æ›´æ–°å‘é‡å­˜å‚¨
            self.vectorstore.add_documents(documents)
            
            # é‡æ–°åˆå§‹åŒ–BM25æ£€ç´¢å™¨
            if BM25Retriever is not None:
                try:
                    self.bm25_retriever = BM25Retriever.from_documents(documents)
                    if hasattr(self.bm25_retriever, 'k'):
                        self.bm25_retriever.k = self.k
                    logger.info("BM25æ£€ç´¢å™¨é‡æ–°åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    logger.warning(f"BM25æ£€ç´¢å™¨é‡æ–°åˆå§‹åŒ–å¤±è´¥: {e}")
                    self.bm25_retriever = SimpleBM25Retriever(documents, self.k)
            else:
                self.bm25_retriever = SimpleBM25Retriever(documents, self.k)
            
            logger.info(f"æ£€ç´¢å™¨æ›´æ–°å®Œæˆï¼Œæ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£")
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            raise


class LangChainEnsembleRetriever:
    """åŸºäºLangChain EnsembleRetrieverçš„å®ç°"""
    
    def __init__(self, 
                 vectorstore: LangChainVectorStore,
                 documents: List[Document] = None,
                 weights: List[float] = [0.5, 0.5]):
        """
        åˆå§‹åŒ–é›†æˆæ£€ç´¢å™¨
        
        Args:
            vectorstore: å‘é‡å­˜å‚¨
            documents: æ–‡æ¡£åˆ—è¡¨
            weights: æ£€ç´¢å™¨æƒé‡
        """
        self.vectorstore = vectorstore
        self.weights = weights
        
        # åˆ›å»ºæ£€ç´¢å™¨åˆ—è¡¨
        retrievers = []
        
        # å‘é‡æ£€ç´¢å™¨
        if vectorstore.get_vectorstore():
            vector_retriever = vectorstore.get_vectorstore().as_retriever()
            retrievers.append(vector_retriever)
        
        # BM25æ£€ç´¢å™¨
        if documents and BM25Retriever is not None:
            try:
                bm25_retriever = BM25Retriever.from_documents(documents)
                retrievers.append(bm25_retriever)
            except Exception as e:
                logger.warning(f"EnsembleRetrieverä¸­BM25åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆ›å»ºé›†æˆæ£€ç´¢å™¨
        if len(retrievers) > 1 and EnsembleRetriever is not None:
            try:
                self.ensemble_retriever = EnsembleRetriever(
                    retrievers=retrievers,
                    weights=weights
                )
            except Exception as e:
                logger.warning(f"EnsembleRetrieveråˆå§‹åŒ–å¤±è´¥: {e}")
                self.ensemble_retriever = retrievers[0] if retrievers else None
        elif len(retrievers) == 1:
            self.ensemble_retriever = retrievers[0]
        else:
            self.ensemble_retriever = None
        
        logger.info(f"é›†æˆæ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ£€ç´¢å™¨æ•°é‡: {len(retrievers)}, æƒé‡: {weights}")
    
    def retrieve(self, query: str, k: int = 5) -> List[Document]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        try:
            if self.ensemble_retriever:
                if hasattr(self.ensemble_retriever, 'k'):
                    self.ensemble_retriever.k = k
                
                if hasattr(self.ensemble_retriever, 'get_relevant_documents'):
                    return self.ensemble_retriever.get_relevant_documents(query)
                elif hasattr(self.ensemble_retriever, 'invoke'):
                    return self.ensemble_retriever.invoke(query)
                else:
                    logger.warning("æ£€ç´¢å™¨æ–¹æ³•è°ƒç”¨å¤±è´¥")
                    return []
            else:
                return []
                
        except Exception as e:
            logger.error(f"é›†æˆæ£€ç´¢å¤±è´¥: {e}")
            return [] 

    def _apply_competition_filter(self, documents: List[Document], competition_type: str, strategy: Dict) -> List[Document]:
        """
        åº”ç”¨ç«èµ›è¿‡æ»¤å’ŒåŠ æƒ
        
        Args:
            documents: åŸå§‹æ£€ç´¢ç»“æœ
            competition_type: ç«èµ›ç±»å‹
            strategy: æ£€ç´¢ç­–ç•¥
            
        Returns:
            è¿‡æ»¤å’ŒåŠ æƒåçš„æ–‡æ¡£åˆ—è¡¨
        """
        try:
            try:
                from config import Config
            except ImportError:
                import sys
                import os
                sys.path.append(os.path.dirname(os.path.dirname(__file__)))
                from config import Config
            competition_mapping = getattr(Config, 'COMPETITION_MAPPING', {})
            
            if competition_type not in competition_mapping:
                logger.warning(f"æœªçŸ¥ç«èµ›ç±»å‹: {competition_type}")
                return documents
            
            comp_info = competition_mapping[competition_type]
            file_pattern = comp_info.get('file_pattern', '')
            boost_keywords = comp_info.get('keywords', [])
            exact_match_boost = comp_info.get('exact_match_boost', 2.0)
            
            logger.info(f"ğŸ¯ åº”ç”¨ç«èµ›è¿‡æ»¤: {competition_type}")
            logger.info(f"ğŸ“ æ–‡ä»¶æ¨¡å¼: {file_pattern}")
            logger.info(f"ğŸ”‘ å…³é”®è¯: {boost_keywords}")
            
            # åˆ†ç¦»åŒ¹é…å’ŒéåŒ¹é…æ–‡æ¡£
            matched_docs = []
            other_docs = []
            
            for doc in documents:
                source = doc.metadata.get('source', '')
                source_name = source.split('/')[-1] if source else ''
                
                # æ£€æŸ¥æ–‡ä»¶ååŒ¹é…
                is_file_match = self._check_file_pattern_match(source_name, file_pattern)
                
                # æ£€æŸ¥å†…å®¹å…³é”®è¯åŒ¹é…
                is_content_match = any(keyword in doc.page_content for keyword in boost_keywords)
                
                if is_file_match or is_content_match:
                    # ä¸ºåŒ¹é…æ–‡æ¡£æ·»åŠ åŠ æƒæ ‡è®°
                    doc.metadata['competition_match'] = True
                    doc.metadata['match_score'] = exact_match_boost
                    matched_docs.append(doc)
                    logger.debug(f"âœ… åŒ¹é…æ–‡æ¡£: {source_name} (æ–‡ä»¶åŒ¹é…: {is_file_match}, å†…å®¹åŒ¹é…: {is_content_match})")
                else:
                    doc.metadata['competition_match'] = False
                    doc.metadata['match_score'] = 1.0
                    other_docs.append(doc)
            
            logger.info(f"ğŸ¯ è¿‡æ»¤ç»“æœ: {len(matched_docs)} ä¸ªåŒ¹é…æ–‡æ¡£, {len(other_docs)} ä¸ªå…¶ä»–æ–‡æ¡£")
            
            # é‡æ–°æ’åºï¼šåŒ¹é…æ–‡æ¡£ä¼˜å…ˆï¼Œç„¶åæ˜¯å…¶ä»–æ–‡æ¡£
            filtered_docs = matched_docs + other_docs[:max(0, self.k - len(matched_docs))]
            
            return filtered_docs[:self.k]
            
        except Exception as e:
            logger.error(f"ç«èµ›è¿‡æ»¤å¤±è´¥: {e}")
            return documents
    
    def _check_file_pattern_match(self, filename: str, pattern: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ¹é…æ¨¡å¼"""
        import fnmatch
        try:
            # ç®€å•çš„æ¨¡å¼åŒ¹é…
            if '*' in pattern:
                return fnmatch.fnmatch(filename, pattern)
            else:
                return pattern in filename
        except Exception as e:
            logger.warning(f"æ–‡ä»¶æ¨¡å¼åŒ¹é…å¤±è´¥: {e}")
            return False 