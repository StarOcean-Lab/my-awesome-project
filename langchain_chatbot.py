#!/usr/bin/env python3
"""
åŸºäºLangChain+Ollamaçš„æ™ºèƒ½å®¢æœæœºå™¨äºº
ä¸“ä¸ºæ³°è¿ªæ¯ç«èµ›é—®ç­”è®¾è®¡
"""

import os
import sys
import glob
import time
import streamlit as st
import pandas as pd
import requests
from typing import List, Dict, Optional, Callable
from loguru import logger
from datetime import datetime
from pathlib import Path
from io import BytesIO

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append('src')

# å¯¼å…¥LangChainç»„ä»¶
from src.langchain_rag import LangChainRAGSystem, RAGResponse
from src.langchain_vectorstore import LangChainVectorStore
from src.langchain_document_loader import LangChainDocumentLoader
from src.langchain_retriever import LangChainHybridRetriever

# å¯¼å…¥ä¼˜åŒ–åçš„RAGç³»ç»Ÿ
from src.optimized_rag_system import OptimizedRAGSystem

# å¯¼å…¥é…ç½®
from config import Config
from optimized_config import OptimizedConfig


def get_ollama_models() -> List[str]:
    """è·å–Ollamaå¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            # è¿‡æ»¤å‡ºé—®ç­”æ¨¡å‹ï¼ˆæ’é™¤embeddingæ¨¡å‹ï¼‰
            qa_models = []
            for model in models:
                model_name = model['name']
                # è¿‡æ»¤æ‰embeddingæ¨¡å‹
                if not any(embed_keyword in model_name.lower() for embed_keyword in 
                          ['embed', 'embedding', 'sentence', 'bge', 'e5']):
                    qa_models.append(model_name)
            return qa_models
        else:
            logger.warning(f"æ— æ³•è·å–Ollamaæ¨¡å‹åˆ—è¡¨: {response.status_code}")
            return []
    except Exception as e:
        logger.error(f"è·å–Ollamaæ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return []


def set_page_style():
    """è®¾ç½®é¡µé¢æ ·å¼"""
    st.markdown("""
    <style>
    /* å¯¼å…¥Googleå­—ä½“ */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    /* ä¸»é¢˜è‰²å½© - ç®€çº¦é£æ ¼ */
    :root {
        --primary-color: #4A90E2;
        --secondary-color: #6B7280;
        --accent-color: #10B981;
        --background-color: #F8FAFC;
        --surface-color: #FFFFFF;
        --text-primary: #1F2937;
        --text-secondary: #6B7280;
        --border-color: #E5E7EB;
        --hover-color: #F3F4F6;
        --success-color: #10B981;
        --warning-color: #F59E0B;
        --error-color: #EF4444;
    }
    
    /* åŸºç¡€æ ·å¼é‡ç½® */
    * {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    }
    
    /* éšè—Streamlité»˜è®¤å…ƒç´  */
    #MainMenu {visibility: hidden;}
    .stDeployButton {display: none;}
    header[data-testid="stHeader"] {display: none;}
    footer {display: none;}
    
    /* ä¸»å®¹å™¨æ ·å¼ */
    .main > div {
        padding: 2rem 3rem;
        max-width: 1200px;
        margin: 0 auto;
        background-color: var(--background-color);
        min-height: 100vh;
    }
    
    /* ä¾§è¾¹æ æ ·å¼ - æ¢å¤å¯ä¼¸ç¼©åŠŸèƒ½ */
    .stSidebar {
        background-color: var(--surface-color);
        border-right: 1px solid var(--border-color);
    }
    
    .stSidebar > div {
        padding: 1.5rem 1rem;
        background-color: var(--surface-color);
    }
    
    /* ä¾§è¾¹æ å†…å®¹æ ·å¼ */
    .stSidebar .stSelectbox label {
        color: var(--text-primary);
        font-weight: 600;
        font-size: 0.875rem;
        margin-bottom: 0.5rem;
    }
    
    .stSidebar .stSelectbox > div > div {
        background-color: var(--surface-color);
        border: 2px solid var(--border-color);
        border-radius: 0.5rem;
        font-size: 0.875rem;
        transition: all 0.2s ease;
    }
    
    .stSidebar .stSelectbox > div > div:hover {
        border-color: var(--primary-color);
        box-shadow: 0 0 0 3px rgba(74, 144, 226, 0.1);
    }
    
    .stSidebar .stButton > button {
        background: linear-gradient(135deg, var(--primary-color), #357ABD);
        color: white;
        border: none;
        border-radius: 0.5rem;
        padding: 0.75rem 1rem;
        font-weight: 600;
        font-size: 0.875rem;
        transition: all 0.2s ease;
        width: 100%;
        margin: 0.25rem 0;
        box-shadow: 0 2px 8px rgba(74, 144, 226, 0.2);
    }
    
    .stSidebar .stButton > button:hover {
        background: linear-gradient(135deg, #357ABD, #2563EB);
        transform: translateY(-1px);
        box-shadow: 0 4px 12px rgba(74, 144, 226, 0.4);
    }
    
    .stSidebar .stMetric {
        background: linear-gradient(135deg, #F8FAFC, #E5E7EB);
        border: 1px solid var(--border-color);
        padding: 1rem;
        border-radius: 0.75rem;
        margin: 0.5rem 0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
    }
    
    .stSidebar .stMetric label {
        color: var(--text-secondary);
        font-size: 0.6rem;
        font-weight: 600;
        text-transform: uppercase;
        letter-spacing: 0.025em;
    }
    
    .stSidebar .stMetric [data-testid="metric-value"] {
        color: var(--primary-color);
        font-size: 0.6rem;
        font-weight: 700;
    }
    
    /* ä¾§è¾¹æ å­æ ‡é¢˜æ ·å¼ */
    .stSidebar h3 {
        color: var(--text-primary);
        font-size: 1.1rem;
        font-weight: 600;
        margin: 1.5rem 0 0.75rem 0;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid var(--primary-color);
    }
    
    /* ä¾§è¾¹æ çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .stSidebar .stSuccess {
        background: linear-gradient(135deg, #10B981, #059669);
        color: white;
        border: none;
        border-radius: 0.5rem;
        padding: 0.75rem;
        font-weight: 600;
        font-size: 0.875rem;
    }
    
    .stSidebar .stWarning {
        background: linear-gradient(135deg, #F59E0B, #D97706);
        color: white;
        border: none;
        border-radius: 0.5rem;
        padding: 0.75rem;
        font-weight: 600;
        font-size: 0.875rem;
    }
    
    .stSidebar .stError {
        background: linear-gradient(135deg, #EF4444, #DC2626);
        color: white;
        border: none;
        border-radius: 0.5rem;
        padding: 0.75rem;
        font-weight: 600;
        font-size: 0.875rem;
    }
    
    .stSidebar .stInfo {
        background: linear-gradient(135deg, #3B82F6, #2563EB);
        color: white;
        border: none;
        border-radius: 0.5rem;
        padding: 0.75rem;
        font-weight: 600;
        font-size: 0.875rem;
    }
    
    /* èŠå¤©æ¶ˆæ¯æ ·å¼ */
    .stChatMessage {
        background-color: var(--surface-color);
        border: 1px solid var(--border-color);
        border-radius: 1rem;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        transition: all 0.2s ease;
    }
    
    .stChatMessage:hover {
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.15);
        transform: translateY(-1px);
    }
    
    .stChatMessage[data-testid="user"] {
        background: linear-gradient(135deg, var(--primary-color), #357ABD);
        color: white;
        border: none;
        margin-left: 3rem;
        box-shadow: 0 4px 16px rgba(74, 144, 226, 0.3);
    }
    
    .stChatMessage[data-testid="assistant"] {
        background: linear-gradient(135deg, var(--surface-color), #F8FAFC);
        color: var(--text-primary);
        margin-right: 3rem;
        border: 1px solid var(--border-color);
    }
    
    /* èŠå¤©è¾“å…¥æ¡†æ ·å¼ - ç°ä»£AIç½‘ç«™é£æ ¼ */
    .stChatInput {
        position: sticky;
        bottom: 0;
        background: var(--surface-color);
        padding: 1rem 0;
        border-top: 1px solid var(--border-color);
    }
    
    .stChatInput > div > div {
        border-radius: 24px;
        border: 2px solid var(--border-color);
        background: var(--surface-color);
        transition: all 0.2s ease;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
    }
    
    .stChatInput > div > div:focus-within {
        border-color: var(--primary-color);
        box-shadow: 0 4px 20px rgba(74, 144, 226, 0.15);
    }
    
    /* æ¨¡å‹é€‰æ‹©å™¨ç°ä»£åŒ–æ ·å¼ */
    .model-selector-container {
        background: linear-gradient(135deg, #ffffff, #f8fafc);
        border: 1px solid #e5e7eb;
        border-radius: 16px;
        padding: 16px;
        margin: 20px 0;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
        transition: all 0.2s ease;
    }
    
    .model-selector-container:hover {
        box-shadow: 0 8px 25px -5px rgba(0, 0, 0, 0.1), 0 8px 10px -6px rgba(0, 0, 0, 0.1);
    }
    
    /* è‡ªå®šä¹‰é€‰æ‹©æ¡†æ ·å¼ */
    .stSelectbox > div > div {
        border-radius: 12px;
        border: 2px solid #e5e7eb;
        background: var(--surface-color);
        transition: all 0.2s ease;
    }
    
    .stSelectbox > div > div:focus-within {
        border-color: var(--primary-color);
        box-shadow: 0 0 0 3px rgba(74, 144, 226, 0.1);
    }
    
    /* çŠ¶æ€æŒ‡ç¤ºå™¨æ ·å¼ */
    .status-indicator {
        display: flex;
        align-items: center;
        justify-content: center;
        height: 40px;
        border-radius: 12px;
        font-size: 12px;
        font-weight: 500;
        transition: all 0.2s ease;
        cursor: pointer;
    }
    
    .status-indicator:hover {
        transform: translateY(-1px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
    }
    
    .status-ready {
        background: linear-gradient(135deg, #dcfce7, #bbf7d0);
        border: 1px solid #bbf7d0;
        color: #166534;
    }
    
    .status-initializing {
        background: linear-gradient(135deg, #fef3c7, #fde68a);
        border: 1px solid #fde68a;
        color: #92400e;
    }
    
    .status-error {
        background: linear-gradient(135deg, #fee2e2, #fecaca);
        border: 1px solid #fecaca;
        color: #991b1b;
    }
    
    /* ä¸»ç•Œé¢å®¹å™¨ä¼˜åŒ– */
    .main-chat-container {
        max-width: 900px;
        margin: 0 auto;
        padding: 0 1rem;
    }
    
    /* èŠå¤©æ¶ˆæ¯ä¼˜åŒ– */
    .stChatMessage {
        margin: 1rem 0;
        padding: 1rem;
        border-radius: 16px;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
        transition: all 0.2s ease;
    }
    
    .stChatMessage:hover {
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.08);
    }
    
    /* ä¾§è¾¹æ ä¼˜åŒ– - ç´§å‡‘å¸ƒå±€ */
    .stSidebar .element-container {
        margin-bottom: 0.5rem;
    }
    
    .stSidebar .stButton > button {
        width: 100%;
        border-radius: 12px;
        border: 2px solid var(--border-color);
        background: var(--surface-color);
        color: var(--text-primary);
        font-weight: 500;
        transition: all 0.2s ease;
    }
    
    .stSidebar .stButton > button:hover {
        border-color: var(--primary-color);
        background: var(--hover-color);
        transform: translateY(-1px);
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background-color: var(--surface-color);
        color: var(--text-primary);
        border: 1px solid var(--border-color);
        border-radius: 0.5rem;
        padding: 0.75rem 1.5rem;
        font-weight: 500;
        font-size: 0.875rem;
        transition: all 0.2s ease;
        margin: 0.25rem;
    }
    
    .stButton > button:hover {
        background-color: var(--hover-color);
        border-color: var(--primary-color);
        transform: translateY(-1px);
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    
    /* ä¸»è¦æŒ‰é’®æ ·å¼ */
    .stButton > button[kind="primary"] {
        background-color: var(--primary-color);
        color: white;
        border-color: var(--primary-color);
    }
    
    .stButton > button[kind="primary"]:hover {
        background-color: #3B82F6;
        border-color: #3B82F6;
    }
    
    /* ç¤ºä¾‹é—®é¢˜æ ·å¼å·²ç§»é™¤ */
    
    /* æˆåŠŸ/é”™è¯¯/è­¦å‘Šæ¶ˆæ¯æ ·å¼ */
    .stSuccess {
        background-color: #F0FDF4;
        border: 1px solid #BBF7D0;
        color: #166534;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    .stError {
        background-color: #FEF2F2;
        border: 1px solid #FECACA;
        color: #991B1B;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    .stWarning {
        background-color: #FFFBEB;
        border: 1px solid #FED7AA;
        color: #92400E;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    .stInfo {
        background-color: #EFF6FF;
        border: 1px solid #BFDBFE;
        color: #1E40AF;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    h1 {
        color: var(--text-primary);
        text-align: center;
        font-size: 2rem;
        font-weight: 700;
        margin-bottom: 1rem;
        letter-spacing: -0.025em;
    }
    
    h2 {
        color: var(--text-primary);
        font-size: 1.5rem;
        font-weight: 600;
        margin: 1.5rem 0 1rem 0;
        letter-spacing: -0.025em;
    }
    
    h3 {
        color: var(--text-primary);
        font-size: 1.25rem;
        font-weight: 600;
        margin: 1rem 0 0.5rem 0;
        letter-spacing: -0.025em;
    }
    
    /* å¡ç‰‡æ ·å¼ */
    .info-card {
        background-color: var(--surface-color);
        border: 1px solid var(--border-color);
        border-radius: 0.75rem;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
    }
    
    .welcome-card {
        background: linear-gradient(135deg, var(--primary-color), #3B82F6);
        color: white;
        border: none;
        text-align: center;
        padding: 3rem 2rem;
        border-radius: 1rem;
        box-shadow: 0 4px 20px rgba(74, 144, 226, 0.2);
        margin: 2rem 0;
    }
    
    .welcome-card h2 {
        color: white;
        margin-bottom: 1rem;
    }
    
    .welcome-card p {
        color: rgba(255, 255, 255, 0.9);
        font-size: 1.1rem;
        margin: 0.5rem 0;
    }
    
    /* åˆ†å‰²çº¿æ ·å¼ */
    .divider {
        border: none;
        height: 1px;
        background-color: var(--border-color);
        margin: 1.5rem 0;
    }
    
    /* åŠ è½½åŠ¨ç”» */
    .stSpinner {
        color: var(--primary-color);
    }
    
    /* è¿›åº¦æ¡æ ·å¼ */
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, var(--primary-color), var(--accent-color));
        border-radius: 0.5rem;
        box-shadow: 0 2px 8px rgba(74, 144, 226, 0.3);
        animation: pulse 2s ease-in-out infinite alternate;
    }
    
    @keyframes pulse {
        from { box-shadow: 0 2px 8px rgba(74, 144, 226, 0.3); }
        to { box-shadow: 0 4px 16px rgba(74, 144, 226, 0.5); }
    }
    
    /* è¿›åº¦çŠ¶æ€æ–‡æœ¬ */
    .progress-status {
        background: linear-gradient(135deg, #F8FAFC, #E5E7EB);
        border: 1px solid var(--border-color);
        border-radius: 0.5rem;
        padding: 0.75rem;
        margin: 0.5rem 0;
        font-family: 'Inter', monospace;
        font-size: 0.875rem;
        color: var(--text-secondary);
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    
    /* è¿›åº¦æ­¥éª¤ä¿¡æ¯ */
    .progress-step {
        background: linear-gradient(135deg, #EFF6FF, #DBEAFE);
        border: 1px solid #BFDBFE;
        border-radius: 0.5rem;
        padding: 0.75rem;
        margin: 0.5rem 0;
        font-family: 'Inter', sans-serif;
        font-size: 0.875rem;
        color: #1E40AF;
        box-shadow: 0 2px 4px rgba(59, 130, 246, 0.1);
    }
    
    /* æ–‡ä»¶ä¸Šä¼ å™¨æ ·å¼ */
    .stFileUploader {
        background-color: var(--surface-color);
        border: 2px dashed var(--border-color);
        border-radius: 0.5rem;
        padding: 1rem;
        text-align: center;
        transition: all 0.2s ease;
    }
    
    .stFileUploader:hover {
        border-color: var(--primary-color);
        background-color: var(--hover-color);
    }
    
    /* å±•å¼€å™¨æ ·å¼ */
    .stExpander {
        background-color: var(--surface-color);
        border: 1px solid var(--border-color);
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    
    .stExpander summary {
        background-color: var(--hover-color);
        color: var(--text-primary);
        font-weight: 500;
        padding: 0.75rem;
        border-radius: 0.5rem 0.5rem 0 0;
    }
    
    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 768px) {
        .main > div {
            padding: 1rem;
        }
        
        .main-chat-container {
            padding: 0 0.5rem;
        }
        
        .model-selector-container {
            margin: 10px 0;
            padding: 12px;
        }
        
        .stChatMessage[data-testid="user"] {
            margin-left: 1rem;
        }
        
        .stChatMessage[data-testid="assistant"] {
            margin-right: 1rem;
        }
        
        /* å“åº”å¼ç¤ºä¾‹é—®é¢˜æ ·å¼å·²ç§»é™¤ */
    }
    </style>
            """, unsafe_allow_html=True)


class LangChainChatbot:
    """åŸºäºLangChain+Ollamaçš„æ™ºèƒ½å®¢æœæœºå™¨äºº"""
    
    def __init__(self, 
                 llm_model: str = "deepseek-r1:7b",
                 embedding_model: str = "./bge-large-zh-v1.5",
                 ollama_base_url: str = "http://localhost:11434",
                 use_optimized: bool = True):
        """
        åˆå§‹åŒ–LangChainèŠå¤©æœºå™¨äºº
        
        Args:
            llm_model: Ollama LLMæ¨¡å‹åç§°
            embedding_model: Ollama embeddingæ¨¡å‹åç§°  
            ollama_base_url: OllamaæœåŠ¡åœ°å€
            use_optimized: æ˜¯å¦ä½¿ç”¨ä¼˜åŒ–åçš„RAGç³»ç»Ÿ
        """
        self.llm_model = llm_model
        self.embedding_model = embedding_model
        self.ollama_base_url = ollama_base_url
        self.use_optimized = use_optimized
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.rag_system = None
        self.document_loader = LangChainDocumentLoader()
        self.vectorstore = None
        self.conversation_history = []
        
        # é…ç½®æ—¥å¿—
        logger.add("langchain_chatbot.log", rotation="1 MB", retention="7 days")
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        self._create_directories()
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        self._initialize_system()
    
    def _create_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        dirs = [
            "vectorstore",
            "knowledge_base", 
            "logs",
            "outputs"
        ]
        
        for dir_path in dirs:
            os.makedirs(dir_path, exist_ok=True)
    
    def _initialize_system(self):
        """åˆå§‹åŒ–LangChain RAGç³»ç»Ÿ"""
        try:
            if self.use_optimized:
                logger.info("ğŸš€ åˆå§‹åŒ–ä¼˜åŒ–åçš„LangChain RAGç³»ç»Ÿ...")
                self.rag_system = OptimizedRAGSystem(
                    llm_model=self.llm_model,
                    base_url=self.ollama_base_url,
                    embedding_model=self.embedding_model
                )
                logger.info("âœ… ä¼˜åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼ˆåŒ…å«5é¡¹æ ¸å¿ƒä¼˜åŒ–ï¼‰")
            else:
                logger.info("åˆå§‹åŒ–ä¼ ç»ŸLangChain RAGç³»ç»Ÿ...")
                self.rag_system = LangChainRAGSystem(
                    model_name=self.llm_model,
                    base_url=self.ollama_base_url,
                    embedding_model=self.embedding_model
                )

            # === æ–°å¢ï¼šä¼˜å…ˆè‡ªåŠ¨åŠ è½½vectorstoreä¸‹çš„å‘é‡æ•°æ®åº“ ===
            auto_loaded = False
            try:
                if hasattr(self.rag_system, 'vectorstore') and self.rag_system.vectorstore:
                    # ä¼˜å…ˆå°è¯•åŠ è½½vectorstore
                    if self.rag_system.vectorstore.load_vectorstore():
                        doc_count = self.rag_system.vectorstore.get_document_count()
                        if doc_count > 0:
                            logger.info(f"âœ… å·²è‡ªåŠ¨åŠ è½½æœ¬åœ°å‘é‡æ•°æ®åº“ï¼Œæ–‡æ¡£æ•°: {doc_count}")
                            auto_loaded = True
                            # === æ–°å¢ï¼šè‡ªåŠ¨è¡¥å…¨RAGé“¾å’Œæ£€ç´¢å™¨ ===
                            try:
                                # ä¼˜åŒ–RAGå’Œä¼ ç»ŸRAGéƒ½å…¼å®¹
                                rag = self.rag_system
                                # æ£€æŸ¥æ˜¯å¦æœ‰RAGé“¾/æ£€ç´¢å™¨
                                rag_chain_ready = False
                                if hasattr(rag, 'rag_chain') and rag.rag_chain:
                                    rag_chain_ready = True
                                if hasattr(rag, 'retriever') and rag.retriever:
                                    rag_chain_ready = True
                                if hasattr(rag, 'advanced_retriever') and rag.advanced_retriever:
                                    rag_chain_ready = True
                                if not rag_chain_ready:
                                    # ä¼˜å…ˆå°è¯•åŠ è½½æ–‡æ¡£ç¼“å­˜
                                    documents = []
                                    if hasattr(rag, '_load_cached_documents'):
                                        documents = rag._load_cached_documents()
                                    if not documents and hasattr(rag, '_reload_source_documents'):
                                        documents = rag._reload_source_documents()
                                    if documents:
                                        # ä¼˜åŒ–RAG
                                        if hasattr(rag, 'advanced_retriever'):
                                            from src.advanced_hybrid_retriever import AdvancedHybridRetriever
                                            rag.advanced_retriever = AdvancedHybridRetriever(
                                                vectorstore=rag.vectorstore,
                                                documents=documents,
                                                vector_weight=getattr(rag, 'vector_weight', 0.4),
                                                bm25_weight=getattr(rag, 'bm25_weight', 0.6),
                                                enable_force_recall=True,
                                                enable_exact_phrase=True,
                                                k=getattr(rag, 'retrieval_k', 10)
                                            )
                                            if hasattr(rag, '_build_optimized_rag_chain'):
                                                rag._build_optimized_rag_chain()
                                        # ä¼ ç»ŸRAG
                                        elif hasattr(rag, '_create_enhanced_retriever'):
                                            from src.langchain_retriever import LangChainHybridRetriever
                                            base_retriever = LangChainHybridRetriever(
                                                vectorstore=rag.vectorstore,
                                                documents=documents,
                                                enable_reranking=True
                                            )
                                            rag.retriever = rag._create_enhanced_retriever(base_retriever, documents)
                                            if hasattr(rag, '_build_rag_chain'):
                                                rag._build_rag_chain()
                                        logger.info("âœ… å·²è‡ªåŠ¨è¡¥å…¨RAGé“¾å’Œæ£€ç´¢å™¨ï¼Œç³»ç»Ÿå¯ç›´æ¥é—®ç­”")
                                    else:
                                        logger.warning("è‡ªåŠ¨è¡¥å…¨RAGé“¾å¤±è´¥ï¼šæœªèƒ½åŠ è½½æ–‡æ¡£ç¼“å­˜æˆ–PDF")
                            except Exception as e:
                                logger.warning(f"è‡ªåŠ¨è¡¥å…¨RAGé“¾å¤±è´¥: {e}")
            except Exception as e:
                logger.warning(f"è‡ªåŠ¨åŠ è½½æœ¬åœ°å‘é‡æ•°æ®åº“å¤±è´¥: {e}")

            # === å…¼å®¹åŸæœ‰è‡ªåŠ¨åŠ è½½é€»è¾‘ ===
            if not auto_loaded:
                self.knowledge_base_auto_loaded = self._check_knowledge_base_status()
            else:
                self.knowledge_base_auto_loaded = True

            if self.knowledge_base_auto_loaded:
                logger.info("âœ… çŸ¥è¯†åº“å·²è‡ªåŠ¨åŠ è½½ï¼Œç³»ç»Ÿå°±ç»ª")
                try:
                    if self.init_document_watcher():
                        if self.start_document_watching():
                            logger.info("âœ… æ–‡æ¡£ç›‘æ§å·²è‡ªåŠ¨å¯åŠ¨ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶å˜æ›´")
                        else:
                            logger.warning("âš ï¸ æ–‡æ¡£ç›‘æ§å¯åŠ¨å¤±è´¥")
                    else:
                        logger.warning("âš ï¸ æ–‡æ¡£ç›‘æ§åˆå§‹åŒ–å¤±è´¥")
                except Exception as e:
                    logger.error(f"æ–‡æ¡£ç›‘æ§è‡ªåŠ¨å¯åŠ¨å¤±è´¥: {e}")
            else:
                logger.info("â„¹ï¸ çŸ¥è¯†åº“æœªè‡ªåŠ¨åŠ è½½ï¼Œéœ€è¦æ‰‹åŠ¨åŠ è½½")
            logger.info("LangChainæ™ºèƒ½å®¢æœç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _check_knowledge_base_status(self) -> bool:
        """æ£€æŸ¥çŸ¥è¯†åº“åŠ è½½çŠ¶æ€"""
        try:
            if self.rag_system and self.rag_system.vectorstore:
                doc_count = self.rag_system.vectorstore.get_document_count()
                return doc_count > 0
            return False
        except Exception as e:
            logger.error(f"æ£€æŸ¥çŸ¥è¯†åº“çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def update_model(self, new_model: str):
        """æ›´æ–°LLMæ¨¡å‹"""
        try:
            logger.info(f"æ›´æ–°æ¨¡å‹ä» {self.llm_model} åˆ° {new_model}")
            self.llm_model = new_model
            
            # é‡æ–°åˆå§‹åŒ–RAGç³»ç»Ÿ
            self.rag_system = LangChainRAGSystem(
                model_name=new_model,
                base_url=self.ollama_base_url,
                embedding_model=self.embedding_model
            )
            
            logger.info(f"æ¨¡å‹æ›´æ–°å®Œæˆ: {new_model}")
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–°æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def load_knowledge_base_incremental(self, pdf_files: List[str] = None, directory: str = None, 
                                       progress_callback: Optional[Callable] = None, force_rebuild: bool = False) -> bool:
        """
        å¢é‡åŠ è½½çŸ¥è¯†åº“
        
        Args:
            pdf_files: PDFæ–‡ä»¶åˆ—è¡¨
            directory: åŒ…å«PDFçš„ç›®å½•
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»º
            
        Returns:
            æ˜¯å¦æˆåŠŸåŠ è½½
        """
        try:
            logger.info("å¼€å§‹å¢é‡åŠ è½½çŸ¥è¯†åº“...")
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶ï¼Œè‡ªåŠ¨æŸ¥æ‰¾dataç›®å½•ä¸‹çš„PDFæ–‡ä»¶
            if not pdf_files and not directory:
                pdf_files = glob.glob("data/*.pdf")
                if not pdf_files:
                    directory = "data"
            
            # ä½¿ç”¨å¢é‡åŠ è½½æ–¹æ³•
            if pdf_files:
                # å¤„ç†å•ä¸ªæ–‡ä»¶æˆ–æ–‡ä»¶åˆ—è¡¨
                success = True
                for pdf_file in pdf_files:
                    file_success = self.rag_system.load_documents_incremental(
                        file_path=pdf_file, 
                        progress_callback=progress_callback,
                        force_rebuild=force_rebuild
                    )
                    success = success and file_success
            elif directory:
                success = self.rag_system.load_documents_incremental(
                    directory_path=directory, 
                    progress_callback=progress_callback,
                    force_rebuild=force_rebuild
                )
            else:
                return False
            
            if success:
                logger.info(f"çŸ¥è¯†åº“å¢é‡åŠ è½½æˆåŠŸ")
                
                # è‡ªåŠ¨å¯åŠ¨æ–‡æ¡£ç›‘æ§
                try:
                    if self.init_document_watcher():
                        if self.start_document_watching():
                            logger.info("âœ… æ–‡æ¡£ç›‘æ§å·²è‡ªåŠ¨å¯åŠ¨ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶å˜æ›´")
                        else:
                            logger.warning("âš ï¸ æ–‡æ¡£ç›‘æ§å¯åŠ¨å¤±è´¥")
                    else:
                        logger.warning("âš ï¸ æ–‡æ¡£ç›‘æ§åˆå§‹åŒ–å¤±è´¥")
                except Exception as e:
                    logger.error(f"æ–‡æ¡£ç›‘æ§è‡ªåŠ¨å¯åŠ¨å¤±è´¥: {e}")
                
                return True
            else:
                logger.error("çŸ¥è¯†åº“å¢é‡åŠ è½½å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"å¢é‡åŠ è½½çŸ¥è¯†åº“æ—¶å‡ºé”™: {e}")
            return False

    def load_knowledge_base(self, pdf_files: List[str] = None, directory: str = None, progress_callback: Optional[Callable] = None) -> bool:
        """
        åŠ è½½çŸ¥è¯†åº“
        
        Args:
            pdf_files: PDFæ–‡ä»¶åˆ—è¡¨
            directory: åŒ…å«PDFçš„ç›®å½•
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            æ˜¯å¦æˆåŠŸåŠ è½½
        """
        try:
            logger.info("å¼€å§‹åŠ è½½çŸ¥è¯†åº“...")
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶ï¼Œè‡ªåŠ¨æŸ¥æ‰¾dataç›®å½•ä¸‹çš„PDFæ–‡ä»¶
            if not pdf_files and not directory:
                pdf_files = glob.glob("data/*.pdf")
                if not pdf_files:
                    logger.warning("æœªæ‰¾åˆ°dataç›®å½•ä¸‹çš„PDFæ–‡ä»¶")
                    return False
            
            # åŠ è½½æ–‡æ¡£åˆ°RAGç³»ç»Ÿï¼Œä¼ é€’è¿›åº¦å›è°ƒ
            if pdf_files:
                success = all(self.rag_system.load_documents(file_path=pdf, progress_callback=progress_callback) for pdf in pdf_files)
            elif directory:
                success = self.rag_system.load_documents(directory_path=directory, progress_callback=progress_callback)
            else:
                return False
            
            if success:
                logger.info(f"çŸ¥è¯†åº“åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(pdf_files) if pdf_files else 'ç›®å½•ä¸­çš„'} ä¸ªæ–‡ä»¶")
                
                # è‡ªåŠ¨å¯åŠ¨æ–‡æ¡£ç›‘æ§
                try:
                    if self.init_document_watcher():
                        if self.start_document_watching():
                            logger.info("âœ… æ–‡æ¡£ç›‘æ§å·²è‡ªåŠ¨å¯åŠ¨ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶å˜æ›´")
                        else:
                            logger.warning("âš ï¸ æ–‡æ¡£ç›‘æ§å¯åŠ¨å¤±è´¥")
                    else:
                        logger.warning("âš ï¸ æ–‡æ¡£ç›‘æ§åˆå§‹åŒ–å¤±è´¥")
                except Exception as e:
                    logger.error(f"æ–‡æ¡£ç›‘æ§è‡ªåŠ¨å¯åŠ¨å¤±è´¥: {e}")
                
                return True
            else:
                logger.error("çŸ¥è¯†åº“åŠ è½½å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"åŠ è½½çŸ¥è¯†åº“æ—¶å‡ºé”™: {e}")
            return False
    
    def answer_question(self, question: str) -> Dict:
        """
        å›ç­”ç”¨æˆ·é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            åŒ…å«ç­”æ¡ˆå’Œç›¸å…³ä¿¡æ¯çš„å­—å…¸
        """
        try:
            if not question.strip():
                return {
                    "question": "",
                    "answer": "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ã€‚",
                    "confidence": 0.0,
                    "sources": [],
                    "retrieval_results": []
                }
            
            logger.info(f"å¤„ç†é—®é¢˜: {question}")
            
            # ä½¿ç”¨LangChain RAGç³»ç»Ÿå›ç­”é—®é¢˜
            rag_response = self.rag_system.answer_question(question)
            
            # è®°å½•å¯¹è¯å†å²
            self.conversation_history.append({
                "timestamp": datetime.now(),
                "question": question,
                "answer": rag_response.answer,
                "confidence": len(rag_response.source_documents) / 10.0  # ç®€å•çš„ç½®ä¿¡åº¦è®¡ç®—
            })
            
            # æ„å»ºå“åº”
            result = {
                "question": rag_response.question,
                "answer": rag_response.answer,
                "confidence": len(rag_response.source_documents) / 10.0,
                "sources": [doc.metadata.get('source', 'æœªçŸ¥æ¥æº') for doc in rag_response.source_documents],
                "source_documents": rag_response.source_documents,  # å®Œæ•´çš„æºæ–‡æ¡£
                "retrieval_results": [
                    {
                        "content": result.document.page_content,  # å®Œæ•´å†…å®¹ï¼Œä¸æˆªæ–­
                        "score": result.score,
                        "source": result.source
                    }
                    for result in rag_response.retrieval_results
                ]
            }
            
            logger.info(f"é—®é¢˜å›ç­”å®Œæˆï¼Œç½®ä¿¡åº¦: {result['confidence']:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"å›ç­”é—®é¢˜æ—¶å‡ºé”™: {e}")
            return {
                "question": question,
                "answer": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}",
                "confidence": 0.0,
                "sources": [],
                "retrieval_results": []
            }
    
    def batch_answer_questions(self, questions: List[str], output_file: str = "batch_results.xlsx") -> List[Dict]:
        """
        æ‰¹é‡å›ç­”é—®é¢˜
        
        Args:
            questions: é—®é¢˜åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            ç»“æœåˆ—è¡¨
        """
        try:
            results = []
            
            logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {len(questions)} ä¸ªé—®é¢˜")
            
            for i, question in enumerate(questions, 1):
                logger.info(f"å¤„ç†ç¬¬ {i}/{len(questions)} ä¸ªé—®é¢˜")
                
                answer_result = self.answer_question(question)
                
                result = {
                    'é—®é¢˜ç¼–å·': f"Q{str(i).zfill(4)}",
                    'é—®é¢˜': question,
                    'å›ç­”': answer_result['answer'],
                    'ç½®ä¿¡åº¦': f"{answer_result['confidence']:.2f}",
                    'æ¥æºæ•°é‡': len(answer_result['sources'])
                }
                
                results.append(result)
            
            # ä¿å­˜ç»“æœåˆ°Excel
            df = pd.DataFrame(results)
            df.to_excel(output_file, index=False)
            logger.info(f"æ‰¹é‡é—®ç­”ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
            return results
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å›ç­”é—®é¢˜æ—¶å‡ºé”™: {e}")
            return []
    
    def extract_competition_info(self, output_file: str = "competition_info.xlsx") -> bool:
        """
        æå–ç«èµ›ä¿¡æ¯
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸæå–
        """
        try:
            logger.info("å¼€å§‹æå–ç«èµ›ä¿¡æ¯...")
            
            # ä½¿ç”¨ä¿¡æ¯æå–æç¤ºæ¨¡æ¿
            if self.rag_system and hasattr(self.rag_system, 'extract_information'):
                competition_data = self.rag_system.extract_information()
            else:
                # å¦‚æœæ²¡æœ‰ä¸“é—¨çš„æå–æ–¹æ³•ï¼Œä½¿ç”¨é—®ç­”æ–¹å¼
                info_questions = [
                    "ç«èµ›åç§°æ˜¯ä»€ä¹ˆï¼Ÿ",
                    "æŠ¥åæ—¶é—´æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ", 
                    "æ¯”èµ›æ—¶é—´æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ",
                    "å‚èµ›å¯¹è±¡æœ‰å“ªäº›è¦æ±‚ï¼Ÿ",
                    "å¥–é¡¹è®¾ç½®æ˜¯æ€æ ·çš„ï¼Ÿ"
                ]
                
                competition_data = []
                for question in info_questions:
                    result = self.answer_question(question)
                    competition_data.append({
                        "ä¿¡æ¯ç±»å‹": question.replace("æ˜¯ä»€ä¹ˆï¼Ÿ", "").replace("æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ", "").replace("æœ‰å“ªäº›è¦æ±‚ï¼Ÿ", "").replace("æ˜¯æ€æ ·çš„ï¼Ÿ", ""),
                        "è¯¦ç»†ä¿¡æ¯": result['answer']
                    })
            
            # ä¿å­˜åˆ°Excel
            if isinstance(competition_data, list):
                df = pd.DataFrame(competition_data)
                df.to_excel(output_file, index=False)
                logger.info(f"ç«èµ›ä¿¡æ¯å·²æå–å¹¶ä¿å­˜åˆ°: {output_file}")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"æå–ç«èµ›ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return False
    
    def get_system_status(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€ä¿¡æ¯"""
        try:
            # å®æ—¶æ£€æŸ¥çŸ¥è¯†åº“çŠ¶æ€
            kb_loaded = self._check_knowledge_base_status()
            doc_count = 0
            
            if self.rag_system and self.rag_system.vectorstore:
                try:
                    doc_count = self.rag_system.vectorstore.get_document_count()
                except:
                    doc_count = 0
            
            status = {
                "llm_model": self.llm_model,
                "embedding_model": self.embedding_model,
                "ollama_url": self.ollama_base_url,
                "conversation_count": len(self.conversation_history),
                "rag_system_ready": self.rag_system is not None,
                "knowledge_base_loaded": kb_loaded,
                "knowledge_base_auto_loaded": getattr(self, 'knowledge_base_auto_loaded', False),
                "document_count": doc_count,
                "last_interaction": self.conversation_history[-1]["timestamp"].isoformat() if self.conversation_history else None
            }
            
            return status
            
        except Exception as e:
            logger.error(f"è·å–ç³»ç»ŸçŠ¶æ€æ—¶å‡ºé”™: {e}")
            return {"error": str(e)}
    
    def rebuild_knowledge_base(self, progress_callback: Optional[Callable] = None) -> bool:
        """
        å®Œå…¨é‡å»ºçŸ¥è¯†åº“
        
        Args:
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            æ˜¯å¦é‡å»ºæˆåŠŸ
        """
        try:
            logger.info("å¼€å§‹é‡å»ºçŸ¥è¯†åº“...")
            
            if not self.rag_system:
                logger.error("RAGç³»ç»Ÿæœªåˆå§‹åŒ–")
                return False
            
            success = self.rag_system.rebuild_knowledge_base(progress_callback)
            
            if success:
                logger.info("çŸ¥è¯†åº“é‡å»ºå®Œæˆ")
                # é‡æ–°å¯åŠ¨æ–‡æ¡£ç›‘æ§
                try:
                    if self.init_document_watcher():
                        if self.start_document_watching():
                            logger.info("âœ… æ–‡æ¡£ç›‘æ§å·²é‡æ–°å¯åŠ¨")
                except Exception as e:
                    logger.error(f"é‡å¯æ–‡æ¡£ç›‘æ§å¤±è´¥: {e}")
            else:
                logger.error("çŸ¥è¯†åº“é‡å»ºå¤±è´¥")
            
            return success
            
        except Exception as e:
            logger.error(f"é‡å»ºçŸ¥è¯†åº“æ—¶å‡ºé”™: {e}")
            return False
    
    def get_version_statistics(self) -> Dict:
        """è·å–ç‰ˆæœ¬ç®¡ç†ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if not self.rag_system:
                return {"error": "RAGç³»ç»Ÿæœªåˆå§‹åŒ–"}
            
            return self.rag_system.get_version_statistics()
            
        except Exception as e:
            logger.error(f"è·å–ç‰ˆæœ¬ç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def cleanup_knowledge_base(self) -> Dict:
        """æ¸…ç†çŸ¥è¯†åº“"""
        try:
            if not self.rag_system:
                return {"error": "RAGç³»ç»Ÿæœªåˆå§‹åŒ–"}
            
            result = self.rag_system.cleanup_knowledge_base()
            logger.info("çŸ¥è¯†åº“æ¸…ç†å®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"æ¸…ç†çŸ¥è¯†åº“å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def detect_pending_updates(self) -> Dict:
        """æ£€æµ‹å¾…æ›´æ–°çš„æ–‡æ¡£"""
        try:
            from src.incremental_document_loader import IncrementalDocumentLoader
            
            # åˆ›å»ºå¢é‡åŠ è½½å™¨
            loader = IncrementalDocumentLoader()
            
            # æ‰«æå¸¸ç”¨ç›®å½•
            directories = ["./data", "./docs"]
            existing_dirs = [d for d in directories if os.path.exists(d)]
            
            if not existing_dirs:
                return {"message": "æœªæ‰¾åˆ°æ–‡æ¡£ç›®å½•"}
            
            # è·å–å¾…æ›´æ–°æ–‡æ¡£
            pending_updates = loader.get_pending_updates(existing_dirs)
            
            return {
                "new_files": pending_updates['new'],
                "modified_files": pending_updates['modified'],
                "unchanged_files": pending_updates['unchanged'],
                "total_new": len(pending_updates['new']),
                "total_modified": len(pending_updates['modified']),
                "total_unchanged": len(pending_updates['unchanged'])
            }
            
        except Exception as e:
            logger.error(f"æ£€æµ‹å¾…æ›´æ–°æ–‡æ¡£å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def init_document_watcher(self) -> bool:
        """åˆå§‹åŒ–æ–‡æ¡£ç›‘æ§å™¨"""
        try:
            if self.rag_system is None:
                logger.error("RAGç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•å¯åŠ¨æ–‡æ¡£ç›‘æ§")
                return False
            
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®
            from config import Config
            from src.document_watcher import WatchConfig
            
            config = WatchConfig(
                watch_directories=Config.WATCH_DIRECTORIES,
                file_patterns=Config.WATCH_FILE_PATTERNS,
                check_interval=Config.WATCH_CHECK_INTERVAL,
                auto_update=Config.WATCH_AUTO_UPDATE,
                min_update_interval=Config.WATCH_MIN_UPDATE_INTERVAL,
                enable_realtime=Config.WATCH_ENABLE_REALTIME
            )
            
            return self.rag_system.init_document_watcher(config)
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ–‡æ¡£ç›‘æ§å™¨å¤±è´¥: {e}")
            return False
    
    def start_document_watching(self) -> bool:
        """å¯åŠ¨æ–‡æ¡£ç›‘æ§"""
        try:
            if self.rag_system is None:
                logger.error("RAGç³»ç»Ÿæœªåˆå§‹åŒ–")
                return False
            
            # å¦‚æœç›‘æ§å™¨æœªåˆå§‹åŒ–ï¼Œå…ˆåˆå§‹åŒ–
            if self.rag_system.document_watcher is None:
                if not self.init_document_watcher():
                    return False
            
            return self.rag_system.start_document_watching()
            
        except Exception as e:
            logger.error(f"å¯åŠ¨æ–‡æ¡£ç›‘æ§å¤±è´¥: {e}")
            return False
    
    def stop_document_watching(self) -> bool:
        """åœæ­¢æ–‡æ¡£ç›‘æ§"""
        try:
            if self.rag_system and self.rag_system.document_watcher:
                return self.rag_system.stop_document_watching()
            return True
            
        except Exception as e:
            logger.error(f"åœæ­¢æ–‡æ¡£ç›‘æ§å¤±è´¥: {e}")
            return False
    
    def check_documents_now(self) -> Dict[str, str]:
        """ç«‹å³æ£€æŸ¥æ–‡æ¡£å˜åŒ–"""
        try:
            if self.rag_system and self.rag_system.document_watcher:
                return self.rag_system.check_documents_now()
            return {}
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ–‡æ¡£å¤±è´¥: {e}")
            return {}
    
    def get_watch_status(self) -> Dict:
        """è·å–æ–‡æ¡£ç›‘æ§çŠ¶æ€"""
        try:
            if self.rag_system and self.rag_system.document_watcher:
                return self.rag_system.get_watch_status()
            return {"enabled": False, "message": "æ–‡æ¡£ç›‘æ§å™¨æœªåˆå§‹åŒ–"}
            
        except Exception as e:
            logger.error(f"è·å–ç›‘æ§çŠ¶æ€å¤±è´¥: {e}")
            return {"enabled": False, "error": str(e)}
    
    def get_monitored_files(self) -> List[Dict]:
        """è·å–ç›‘æ§çš„æ–‡ä»¶åˆ—è¡¨"""
        try:
            if self.rag_system and self.rag_system.document_watcher:
                return self.rag_system.get_monitored_files()
            return []
            
        except Exception as e:
            logger.error(f"è·å–ç›‘æ§æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []


def create_streamlit_interface():
    """åˆ›å»ºStreamlit Webç•Œé¢"""
    
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title="ğŸ¤– æ™ºèƒ½å®¢æœæœºå™¨äºº",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # è®¾ç½®é¡µé¢æ ·å¼
    set_page_style()
    
    # ä¸»æ ‡é¢˜ - ç®€çº¦é£æ ¼
    st.markdown("""
    <div style="text-align: center; margin-bottom: 2rem;">
        <h1 style="
            color: #1F2937;
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            letter-spacing: -0.025em;
        ">
            ğŸ¤– æ™ºèƒ½å®¢æœæœºå™¨äºº
        </h1>
        <p style="
            color: #6B7280;
            font-size: 1.1rem;
            font-weight: 400;
            margin: 0;
        ">
            åŸºäº LangChain + Ollama çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿ
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # è·å–å¯ç”¨æ¨¡å‹
    available_models = get_ollama_models()
    if not available_models:
        available_models = [Config.LLM_MODEL]  # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
    
    # åˆå§‹åŒ–session state
    if 'chatbot' not in st.session_state:
        st.session_state.chatbot = None
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'current_model' not in st.session_state:
        st.session_state.current_model = available_models[0] if available_models else Config.LLM_MODEL
    if 'use_optimized' not in st.session_state:
        st.session_state.use_optimized = True  # é»˜è®¤ä½¿ç”¨ä¼˜åŒ–æ¨¡å¼
    if 'auto_init_done' not in st.session_state:
        st.session_state.auto_init_done = False

    # ä¾§è¾¹æ 
    with st.sidebar:
        st.title("âš™ï¸ ç³»ç»Ÿæ§åˆ¶")
        
        # RAGç³»ç»Ÿé…ç½®
        st.subheader("ğŸš€ RAGç³»ç»Ÿé…ç½®")
        
        # ä¼˜åŒ–æ¨¡å¼é€‰æ‹©
        use_optimized = st.toggle(
            "ğŸ¯ å¯ç”¨ä¼˜åŒ–æ¨¡å¼",
            value=st.session_state.use_optimized,
            help="å¯ç”¨5é¡¹æ ¸å¿ƒä¼˜åŒ–ï¼šæ··åˆæ£€ç´¢+é‡æ’åº+å®ä½“å¥–åŠ±+æ–‡æ¡£å¢å¼º+æç¤ºä¼˜åŒ–"
        )
        
        # å¦‚æœä¼˜åŒ–æ¨¡å¼æ”¹å˜äº†ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–
        if use_optimized != st.session_state.use_optimized:
            st.session_state.use_optimized = use_optimized
            st.session_state.chatbot = None
            st.session_state.auto_init_done = False
            st.info("ğŸ”„ ä¼˜åŒ–æ¨¡å¼å·²æ›´æ”¹ï¼Œç³»ç»Ÿå°†é‡æ–°åˆå§‹åŒ–")
            st.rerun()
        
        # ä¼˜åŒ–æ¨¡å¼è¯´æ˜
        if st.session_state.use_optimized:
            st.success("âœ… ä¼˜åŒ–æ¨¡å¼å·²å¯ç”¨")
            with st.expander("ğŸ“‹ ä¼˜åŒ–åŠŸèƒ½è¯¦æƒ…", expanded=False):
                st.markdown("""
                **ğŸ¯ 5é¡¹æ ¸å¿ƒä¼˜åŒ–**ï¼š
                1. **æ··åˆæ£€ç´¢**: BM25+å‘é‡æ£€ç´¢èåˆ
                2. **é‡æ’åº**: Cross-Encoderæ™ºèƒ½é‡æ’
                3. **å®ä½“å¥–åŠ±**: å…³é”®è¯å‘½ä¸­åŠ åˆ†
                4. **æ–‡æ¡£å¢å¼º**: ç« èŠ‚åˆ‡åˆ†+æ ‡é¢˜æ‹¼æ¥
                5. **æç¤ºä¼˜åŒ–**: Few-shotæ™ºèƒ½æç¤º
                """)
        else:
            st.info("â„¹ï¸ ä½¿ç”¨ä¼ ç»ŸRAGæ¨¡å¼")

        # è‡ªåŠ¨ç³»ç»Ÿåˆå§‹åŒ–
        if st.session_state.chatbot is None and not st.session_state.auto_init_done:
            system_type = "ä¼˜åŒ–åçš„RAGç³»ç»Ÿ" if st.session_state.use_optimized else "ä¼ ç»ŸRAGç³»ç»Ÿ"
            with st.spinner(f"ğŸš€ æ­£åœ¨è‡ªåŠ¨åˆå§‹åŒ–{system_type}..."):
                try:
                    st.session_state.chatbot = LangChainChatbot(
                        llm_model=st.session_state.current_model,
                        embedding_model="./bge-large-zh-v1.5",
                        ollama_base_url=Config.OLLAMA_BASE_URL,
                        use_optimized=st.session_state.use_optimized
                    )
                    st.session_state.auto_init_done = True
                    success_msg = f"âœ… {system_type}è‡ªåŠ¨åˆå§‹åŒ–å®Œæˆï¼"
                    if st.session_state.use_optimized:
                        success_msg += "\nğŸ¯ 5é¡¹æ ¸å¿ƒä¼˜åŒ–å·²å¯ç”¨"
                    st.success(success_msg)
                    st.rerun()  # åˆ·æ–°é¡µé¢çŠ¶æ€
                except Exception as e:
                    st.error(f"âŒ è‡ªåŠ¨åˆå§‹åŒ–å¤±è´¥: {e}")
                    st.info("ğŸ’¡ è¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        
        # ç³»ç»ŸçŠ¶æ€æ˜¾ç¤º - ç§»å‡ºåˆå§‹åŒ–æ¡ä»¶ï¼Œç‹¬ç«‹æ˜¾ç¤º
        if st.session_state.chatbot:
            # çŠ¶æ€æ ‡é¢˜å’Œåˆ·æ–°æŒ‰é’®
            col1, col2 = st.columns([3, 1])
            with col1:
                st.subheader("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
            with col2:
                if st.button("ğŸ”„", help="åˆ·æ–°çŠ¶æ€", key="refresh_status"):
                    # å¼ºåˆ¶åˆ·æ–°çŠ¶æ€
                    st.session_state.system_status_cache = st.session_state.chatbot.get_system_status()
                    st.session_state.last_status_update = time.time()
                    st.rerun()
            
            # æ·»åŠ çŠ¶æ€ç¼“å­˜ï¼Œé¿å…é¢‘ç¹è°ƒç”¨
            if 'system_status_cache' not in st.session_state:
                st.session_state.system_status_cache = None
                st.session_state.last_status_update = 0
            
            # æ¯30ç§’æ›´æ–°ä¸€æ¬¡çŠ¶æ€ï¼Œé¿å…é¢‘ç¹è°ƒç”¨
            current_time = time.time()
            if (st.session_state.system_status_cache is None or 
                current_time - st.session_state.last_status_update > 30):
                st.session_state.system_status_cache = st.session_state.chatbot.get_system_status()
                st.session_state.last_status_update = current_time
            
            status = st.session_state.system_status_cache
            
            # åˆ›å»ºçŠ¶æ€å¡ç‰‡
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ğŸ’¬ å¯¹è¯æ¬¡æ•°", status.get("conversation_count", 0))
            with col2:
                st.metric("ğŸ¤– å½“å‰æ¨¡å‹", status.get("llm_model", "æœªçŸ¥")[-15:])
            
            # ç¬¬äºŒè¡ŒçŠ¶æ€å¡ç‰‡
            col3, col4 = st.columns(2)
            with col3:
                st.metric("ğŸ“š æ–‡æ¡£æ•°é‡", status.get("document_count", 0))
            with col4:
                auto_loaded = "âœ… è‡ªåŠ¨" if status.get("knowledge_base_auto_loaded") else "âš ï¸ æ‰‹åŠ¨"
                st.metric("ğŸ”„ åŠ è½½æ–¹å¼", auto_loaded)
            
            # ç³»ç»ŸçŠ¶æ€æŒ‡ç¤ºå™¨
            if status.get("rag_system_ready"):
                st.success("ğŸŸ¢ RAGç³»ç»Ÿ: å°±ç»ª")
            else:
                st.warning("ğŸŸ¡ RAGç³»ç»Ÿ: åˆå§‹åŒ–ä¸­...")
            
            # çŸ¥è¯†åº“çŠ¶æ€æ˜¾ç¤º
            if status.get("knowledge_base_loaded"):
                if status.get("knowledge_base_auto_loaded"):
                    st.success("ğŸŸ¢ çŸ¥è¯†åº“: å·²è‡ªåŠ¨åŠ è½½")
                else:
                    st.success("ğŸŸ¢ çŸ¥è¯†åº“: å·²æ‰‹åŠ¨åŠ è½½")
            else:
                st.warning("ğŸŸ¡ çŸ¥è¯†åº“: æœªåŠ è½½")
        
            st.markdown('<hr class="divider">', unsafe_allow_html=True)
            
            # ç‰ˆæœ¬ç®¡ç†ç»Ÿè®¡
            st.subheader("ğŸ“Š ç‰ˆæœ¬ç®¡ç†ç»Ÿè®¡")
            
            # æ·»åŠ ç‰ˆæœ¬ç»Ÿè®¡ç¼“å­˜
            if 'version_stats_cache' not in st.session_state:
                st.session_state.version_stats_cache = None
                st.session_state.last_version_update = 0
            
            # æ¯60ç§’æ›´æ–°ä¸€æ¬¡ç‰ˆæœ¬ç»Ÿè®¡
            if (st.session_state.version_stats_cache is None or 
                current_time - st.session_state.last_version_update > 60):
                try:
                    st.session_state.version_stats_cache = st.session_state.chatbot.get_version_statistics()
                    st.session_state.last_version_update = current_time
                except Exception as e:
                    logger.debug(f"è·å–ç‰ˆæœ¬ç»Ÿè®¡å¼‚å¸¸: {e}")
                    st.session_state.version_stats_cache = {"error": str(e)}
            
            version_stats = st.session_state.version_stats_cache
            
            if "error" not in version_stats:
                if version_stats.get("versioning_enabled"):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ğŸ“„ è·Ÿè¸ªæ–‡æ¡£", version_stats.get("total_documents", 0))
                    with col2:
                        st.metric("ğŸ§© æ–‡æ¡£ç‰‡æ®µ", version_stats.get("total_chunks", 0))
                    with col3:
                        avg_chunks = version_stats.get("average_chunks_per_doc", 0)
                        st.metric("ğŸ“Š å¹³å‡ç‰‡æ®µ", f"{avg_chunks:.1f}")
                    
                    if version_stats.get("latest_update"):
                        st.caption(f"æœ€åæ›´æ–°: {version_stats.get('latest_update')}")
                else:
                    st.info("ç‰ˆæœ¬ç®¡ç†åŠŸèƒ½æœªå¯ç”¨")
            else:
                st.error(f"è·å–ç‰ˆæœ¬ç»Ÿè®¡å¤±è´¥: {version_stats.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            st.markdown('<hr class="divider">', unsafe_allow_html=True)
            
            # çŸ¥è¯†åº“ç®¡ç†
            st.subheader("ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
            
            pdf_files = glob.glob("data/*.pdf")
            if pdf_files:
                st.info(f"ğŸ“„ å‘ç° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
                
                # æ ¹æ®çŸ¥è¯†åº“çŠ¶æ€æ˜¾ç¤ºä¸åŒçš„çŠ¶æ€ä¿¡æ¯
                if status.get("knowledge_base_loaded"):
                    if status.get("knowledge_base_auto_loaded"):
                        # å·²è‡ªåŠ¨åŠ è½½ï¼Œæ˜¾ç¤ºçŠ¶æ€
                        st.success("âœ… çŸ¥è¯†åº“å·²è‡ªåŠ¨åŠ è½½ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹æ–‡ä»¶å˜æ›´")
                    else:
                        # å·²æ‰‹åŠ¨åŠ è½½ï¼Œæ˜¾ç¤ºçŠ¶æ€
                        st.success("âœ… çŸ¥è¯†åº“å·²æ‰‹åŠ¨åŠ è½½å®Œæˆ")
                else:
                    # æœªåŠ è½½ï¼Œæ˜¾ç¤ºåŠ è½½æŒ‰é’®
                    st.warning("âš ï¸ çŸ¥è¯†åº“å°šæœªåŠ è½½ï¼Œè¯·æ‰‹åŠ¨åŠ è½½")
                
                # æ£€æµ‹å¾…æ›´æ–°æ–‡æ¡£
                if st.button("ğŸ” æ£€æµ‹æ–‡æ¡£å˜åŒ–", help="æ‰«æå¹¶æ£€æµ‹éœ€è¦æ›´æ–°çš„æ–‡æ¡£"):
                    with st.spinner("æ­£åœ¨æ£€æµ‹æ–‡æ¡£å˜åŒ–..."):
                        try:
                            pending_updates = st.session_state.chatbot.detect_pending_updates()
                            if "error" not in pending_updates:
                                st.success("âœ… æ–‡æ¡£å˜åŒ–æ£€æµ‹å®Œæˆ")
                                
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("ğŸ†• æ–°å¢æ–‡ä»¶", pending_updates.get("total_new", 0))
                                with col2:
                                    st.metric("ğŸ“ ä¿®æ”¹æ–‡ä»¶", pending_updates.get("total_modified", 0))
                                with col3:
                                    st.metric("âœ… æœªå˜åŒ–æ–‡ä»¶", pending_updates.get("total_unchanged", 0))
                                
                                # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                                if pending_updates.get("details"):
                                    with st.expander("ğŸ“‹ è¯¦ç»†å˜åŒ–ä¿¡æ¯"):
                                        for file_name, info in pending_updates["details"].items():
                                            if info["status"] != "unchanged":
                                                st.write(f"ğŸ“„ {file_name}: {info['status']}")
                                                if "reason" in info:
                                                    st.caption(f"   åŸå› : {info['reason']}")
                            else:
                                st.error(f"æ£€æµ‹å¤±è´¥: {pending_updates.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        except Exception as e:
                            st.error(f"æ£€æµ‹æ–‡æ¡£å˜åŒ–æ—¶å‡ºé”™: {e}")
                
                st.markdown("---")
                
                # çŸ¥è¯†åº“æ“ä½œæŒ‰é’®
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if st.button("ğŸ”„ å¢é‡æ›´æ–°", help="ä»…å¤„ç†æ–°å¢æˆ–ä¿®æ”¹çš„æ–‡æ¡£", key="incremental_update"):
                        with st.spinner("æ­£åœ¨è¿›è¡Œå¢é‡æ›´æ–°..."):
                            def incremental_progress_callback(progress_info):
                                st.write(f"ğŸ“Š {progress_info.step_name}: {progress_info.description}")
                            
                            success = st.session_state.chatbot.load_knowledge_base_incremental(pdf_files, progress_callback=incremental_progress_callback)
                            if success:
                                st.success("âœ… å¢é‡æ›´æ–°æˆåŠŸï¼")
                                st.rerun()
                            else:
                                st.error("âŒ å¢é‡æ›´æ–°å¤±è´¥")
                
                with col2:
                    if st.button("ğŸ”¨ å®Œå…¨é‡å»º", help="æ¸…ç©ºç°æœ‰æ•°æ®å¹¶é‡æ–°æ„å»ºçŸ¥è¯†åº“", key="rebuild_kb"):
                        with st.spinner("æ­£åœ¨é‡å»ºçŸ¥è¯†åº“..."):
                            success = st.session_state.chatbot.rebuild_knowledge_base()
                            if success:
                                st.success("âœ… çŸ¥è¯†åº“é‡å»ºæˆåŠŸï¼")
                                st.rerun()
                            else:
                                st.error("âŒ çŸ¥è¯†åº“é‡å»ºå¤±è´¥")
                
                with col3:
                    if st.button("ğŸ§¹ æ¸…ç†æ•°æ®", help="æ¸…ç†å­¤ç«‹çš„ç‰ˆæœ¬ä¿¡æ¯", key="cleanup_kb"):
                        with st.spinner("æ­£åœ¨æ¸…ç†çŸ¥è¯†åº“..."):
                            try:
                                result = st.session_state.chatbot.cleanup_knowledge_base()
                                if "error" not in result:
                                    removed_count = result.get("orphaned_removed", 0)
                                    if removed_count > 0:
                                        st.success(f"âœ… æ¸…ç†å®Œæˆï¼Œç§»é™¤äº† {removed_count} ä¸ªå­¤ç«‹ç‰ˆæœ¬")
                                    else:
                                        st.info("âœ… æ¸…ç†å®Œæˆï¼Œæ²¡æœ‰å‘ç°å­¤ç«‹æ•°æ®")
                                else:
                                    st.error(f"æ¸…ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                            except Exception as e:
                                st.error(f"æ¸…ç†æ—¶å‡ºé”™: {e}")
                
                st.markdown("---")
                
                if st.button("ğŸ“¥ ä¼ ç»ŸåŠ è½½", key="load_kb", help="ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼é‡æ–°åŠ è½½æ‰€æœ‰PDFæ–‡ä»¶"):
                    if st.session_state.chatbot:
                        # åˆ›å»ºè¿›åº¦æ¡å®¹å™¨
                        progress_container = st.container()
                        
                        with progress_container:
                            # è¿›åº¦æ¡æ ‡é¢˜ - ä½¿ç”¨empty()å®¹å™¨ä»¥ä¾¿åç»­æ¸…é™¤
                            title_container = st.empty()
                            title_container.markdown("""
                            <div style="
                                background: linear-gradient(135deg, var(--primary-color), #3B82F6);
                                color: white;
                                padding: 1rem;
                                border-radius: 0.5rem;
                                text-align: center;
                                font-weight: 600;
                                margin: 1rem 0;
                                box-shadow: 0 2px 8px rgba(74, 144, 226, 0.3);
                            ">
                                ğŸš€ æ­£åœ¨åŠ è½½çŸ¥è¯†åº“...
    </div>
    """, unsafe_allow_html=True)
        
                            # åˆå§‹åŒ–è¿›åº¦æ¡
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            step_info = st.empty()
                            
                            # è¿›åº¦å›è°ƒå‡½æ•°
                            def progress_callback(progress_info):
                                from src.progress_manager import ProgressInfo
                                
                                # æ›´æ–°è¿›åº¦æ¡
                                progress_percentage = progress_info.percentage / 100
                                progress_bar.progress(progress_percentage)
                                
                                # æ›´æ–°çŠ¶æ€æ–‡æœ¬
                                status_text.markdown(f"""
                                <div class="progress-status">
                                    ğŸ“Š <strong>{progress_info.step_name}</strong> ({progress_info.current_step}/{progress_info.total_steps}) - {progress_info.percentage:.1f}%
        </div>
        """, unsafe_allow_html=True)
        
                                # æ›´æ–°è¯¦ç»†ä¿¡æ¯
                                step_info.markdown(f"""
                                <div class="progress-step">
                                    ğŸ”„ {progress_info.description}
                                </div>
                                """, unsafe_allow_html=True)
                                
                                # å¦‚æœå¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                                if progress_info.status.value == "failed":
                                    st.error(f"âŒ åŠ è½½å¤±è´¥: {progress_info.error_message}")
                        
                        # æ‰§è¡ŒåŠ è½½
                        success = st.session_state.chatbot.load_knowledge_base(pdf_files, progress_callback=progress_callback)
                        
                        # æ¸…ç†æ‰€æœ‰è¿›åº¦æ˜¾ç¤ºç»„ä»¶ï¼ŒåŒ…æ‹¬æ ‡é¢˜
                        title_container.empty()
                        progress_bar.empty()
                        status_text.empty()
                        step_info.empty()
                        
                        if success:
                            st.success(f"âœ… æˆåŠŸåŠ è½½ {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
                            # å¼ºåˆ¶åˆ·æ–°é¡µé¢çŠ¶æ€
                            st.rerun()
                        else:
                            st.error("âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥")
                    else:
                        st.warning("âš ï¸ è¯·å…ˆåˆå§‹åŒ–ç³»ç»Ÿ")
            else:
                st.warning("âš ï¸ æœªæ‰¾åˆ°PDFæ–‡ä»¶")
                st.info("ğŸ’¡ è¯·å°†PDFæ–‡ä»¶æ”¾å…¥dataç›®å½•")
            
            st.markdown('<hr class="divider">', unsafe_allow_html=True)
            
            # æ‰¹é‡é—®ç­”
            st.subheader("ğŸ“ æ‰¹é‡é—®ç­”")
            
            uploaded_questions = st.file_uploader(
                "ä¸Šä¼ é—®é¢˜Excelæ–‡ä»¶",
                type=['xlsx', 'xls'],
                help="Excelæ–‡ä»¶åº”åŒ…å«'é—®é¢˜'åˆ—"
            )
            
            if uploaded_questions and st.button("ğŸš€ å¼€å§‹æ‰¹é‡é—®ç­”", key="batch_qa"):
                if st.session_state.chatbot:
                    with st.spinner("æ­£åœ¨æ‰¹é‡å¤„ç†é—®é¢˜..."):
                        try:
                            df = pd.read_excel(uploaded_questions)
                            questions = df['é—®é¢˜'].tolist()
                            
                            results = st.session_state.chatbot.batch_answer_questions(
                                questions, 
                                f"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                            )
                            
                            if results:
                                st.success(f"âœ… æˆåŠŸå¤„ç† {len(results)} ä¸ªé—®é¢˜")
                                
                                # åˆ›å»ºExcelæ–‡ä»¶çš„å­—èŠ‚æµæ•°æ®
                                excel_buffer = BytesIO()
                                pd.DataFrame(results).to_excel(excel_buffer, index=False, engine='openpyxl')
                                excel_data = excel_buffer.getvalue()
                                
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ç»“æœæ–‡ä»¶",
                                    data=excel_data,
                                    file_name=f"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                            else:
                                st.error("âŒ æ‰¹é‡å¤„ç†å¤±è´¥")
                                
                        except Exception as e:
                            st.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
                else:
                    st.warning("âš ï¸ è¯·å…ˆåˆå§‹åŒ–ç³»ç»Ÿ")

    # ä¸»ç•Œé¢ - èŠå¤©åŒºåŸŸ
    # åˆ›å»ºä¸»èŠå¤©å®¹å™¨
    main_container = st.container()
    
    with main_container:
        st.markdown('<div class="main-chat-container">', unsafe_allow_html=True)
        
        if st.session_state.chatbot is None:
            st.markdown("""
            <div class="welcome-card">
                <h2>ğŸš€ æ¬¢è¿ä½¿ç”¨æ™ºèƒ½å®¢æœæœºå™¨äººï¼</h2>
                <p>ç³»ç»Ÿæ­£åœ¨è‡ªåŠ¨åˆå§‹åŒ–ï¼Œè¯·ç¨å€™...</p>
                <p style="opacity: 0.9;">ğŸ’¡ åˆå§‹åŒ–å®Œæˆåå¯å¼€å§‹é—®ç­”</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            # æ£€æŸ¥çŸ¥è¯†åº“çŠ¶æ€å¹¶æ˜¾ç¤ºç›¸åº”æç¤º
            status = st.session_state.chatbot.get_system_status()
            
            if not status.get("knowledge_base_loaded"):
                st.markdown("""
                <div class="welcome-card">
                    <h2>âš ï¸ çŸ¥è¯†åº“å°šæœªåŠ è½½</h2>
                    <p>ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œä½†çŸ¥è¯†åº“å°šæœªåŠ è½½</p>
                    <p style="opacity: 0.9;">ğŸ’¡ è¯·åœ¨ä¾§è¾¹æ ä¸­åŠ è½½çŸ¥è¯†åº“ä»¥è·å¾—å‡†ç¡®çš„ç«èµ›ä¿¡æ¯</p>
                </div>
                """, unsafe_allow_html=True)
            elif status.get("knowledge_base_auto_loaded"):
                st.markdown("""
                <div class="welcome-card">
                    <h2>âœ… ç³»ç»Ÿå°±ç»ªï¼</h2>
                    <p>çŸ¥è¯†åº“å·²è‡ªåŠ¨åŠ è½½ï¼ŒåŒ…å« {doc_count} ä¸ªæ–‡æ¡£</p>
                    <p style="opacity: 0.9;">ğŸ¯ æ‚¨å¯ä»¥å¼€å§‹æé—®å…³äºç«èµ›çš„ä»»ä½•é—®é¢˜</p>
                </div>
                """.format(doc_count=status.get("document_count", 0)), unsafe_allow_html=True)
            
            # èŠå¤©ç•Œé¢æ ‡é¢˜
            st.markdown("""
            <div class="info-card">
                <h2 style="color: #4A90E2; text-align: center; margin-bottom: 1rem;">
                    ğŸ’¬ æ™ºèƒ½é—®ç­”å¯¹è¯
                </h2>
            </div>
            """, unsafe_allow_html=True)
            
            # èŠå¤©å†å²å®¹å™¨
            chat_container = st.container()
            
            # æ˜¾ç¤ºèŠå¤©å†å²
            with chat_container:
                for message in st.session_state.messages:
                    with st.chat_message(message["role"]):
                        st.markdown(message["content"])
            
            # åˆ›å»ºè¾“å…¥åŒºåŸŸçš„å®¹å™¨ - ç°ä»£AIç½‘ç«™é£æ ¼çš„è¾“å…¥åŒºåŸŸ
            input_container = st.container()
            
            with input_container:
                # æ¨¡å‹é€‰æ‹©å’Œè¾“å…¥æ¡†ç»„åˆåŒºåŸŸ
                st.markdown("""
                <div class="model-selector-container">
                """, unsafe_allow_html=True)
                
                # æ¨¡å‹é€‰æ‹©è¡Œ
                col1, col2, col3 = st.columns([1, 2, 1])
                
                with col1:
                    st.markdown("""
                    <div style="
                        display: flex;
                        align-items: center;
                        height: 40px;
                        font-weight: 500;
                        color: #374151;
                        font-size: 14px;
                    ">
                        ğŸ¤– æ¨¡å‹é€‰æ‹©
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    selected_model = st.selectbox(
                        "é€‰æ‹©AIæ¨¡å‹",  # æä¾›æœ‰æ„ä¹‰çš„æ ‡ç­¾
                        available_models,
                        index=available_models.index(st.session_state.current_model) if st.session_state.current_model in available_models else 0,
                        key="model_selector_main",
                        help="é€‰æ‹©ç”¨äºå›ç­”é—®é¢˜çš„AIæ¨¡å‹",
                        label_visibility="collapsed"  # éšè—æ ‡ç­¾æ˜¾ç¤º
                    )
                
                    # å¤„ç†æ¨¡å‹åˆ‡æ¢
                    if selected_model != st.session_state.current_model:
                        if st.session_state.chatbot:
                            with st.spinner(f"æ­£åœ¨åˆ‡æ¢åˆ° {selected_model}..."):
                                success = st.session_state.chatbot.update_model(selected_model)
                                if success:
                                    st.session_state.current_model = selected_model
                                    st.success(f"âœ… å·²åˆ‡æ¢åˆ°æ¨¡å‹: {selected_model}")
                                    st.rerun()
                                else:
                                    st.error("âŒ æ¨¡å‹åˆ‡æ¢å¤±è´¥")
                        else:
                            st.session_state.current_model = selected_model
                
                with col3:
                    # ç³»ç»ŸçŠ¶æ€æŒ‡ç¤ºå™¨
                    if st.session_state.chatbot:
                        status = st.session_state.chatbot.get_system_status()
                        if status.get("rag_system_ready") and status.get("knowledge_base_loaded"):
                            st.markdown("""
                            <div class="status-indicator status-ready">
                                ğŸŸ¢ ç³»ç»Ÿå°±ç»ª
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.markdown("""
                            <div class="status-indicator status-initializing">
                                ğŸŸ¡ åˆå§‹åŒ–ä¸­
                            </div>
                            """, unsafe_allow_html=True)
                    else:
                        st.markdown("""
                        <div class="status-indicator status-error">
                            ğŸ”´ æœªåˆå§‹åŒ–
                        </div>
                        """, unsafe_allow_html=True)
                
                st.markdown("</div>", unsafe_allow_html=True)
            
            # ç”¨æˆ·è¾“å…¥ - ç°ä»£åŒ–çš„èŠå¤©è¾“å…¥æ¡†
            if prompt := st.chat_input("ğŸ’­ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", key="user_input"):
                # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # ç”Ÿæˆå¹¶æ˜¾ç¤ºåŠ©æ‰‹å›ç­”
                with st.chat_message("assistant"):
                    # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
                    if not st.session_state.chatbot:
                        st.error("âŒ ç³»ç»Ÿæœªåˆå§‹åŒ–")
                        st.stop()
                    
                    status = st.session_state.chatbot.get_system_status()
                    if not status.get("knowledge_base_loaded"):
                        st.warning("âš ï¸ çŸ¥è¯†åº“æœªåŠ è½½ï¼Œå›ç­”å¯èƒ½ä¸å¤Ÿå‡†ç¡®")
                    
                    with st.spinner("ğŸ¤” AIæ­£åœ¨æ€è€ƒä¸­..."):
                        result = st.session_state.chatbot.answer_question(prompt)
                    
                    response = result['answer']
                    st.markdown(response)
                    
                    # æ˜¾ç¤ºæ›´è¯¦ç»†çš„ä¸Šä¸‹æ–‡æ¥æºä¿¡æ¯
                    if result.get('source_documents'):
                        with st.expander("ğŸ“– æŸ¥çœ‹å®Œæ•´ä¸Šä¸‹æ–‡æ¥æº", expanded=False):
                            source_docs = result['source_documents']
                            
                            # ç»Ÿè®¡ä¿¡æ¯
                            total_docs = len(source_docs)
                            total_chars = sum(len(doc.page_content) for doc in source_docs)
                            avg_length = total_chars / total_docs if total_docs > 0 else 0
                            
                            st.markdown(f"""
                            **ğŸ“Š ä¸Šä¸‹æ–‡ç»Ÿè®¡:**
                            - ğŸ“„ æ–‡æ¡£æ•°é‡: {total_docs}
                            - ğŸ“ æ€»å­—ç¬¦æ•°: {total_chars:,}
                            - ğŸ“ å¹³å‡é•¿åº¦: {avg_length:.0f} å­—ç¬¦/æ–‡æ¡£
                            """)
                            
                            st.markdown("---")
                            
                            # è¯¦ç»†æ–‡æ¡£å†…å®¹
                            for i, doc in enumerate(source_docs, 1):
                                st.markdown(f"**ğŸ“„ æ–‡æ¡£ {i}: {doc.metadata.get('source', 'æœªçŸ¥æ¥æº').split('/')[-1]}**")
                                
                                if doc.page_content.strip():
                                    with st.container():
                                        st.text_area(
                                            f"æ–‡æ¡£ {i} å†…å®¹",
                                            value=doc.page_content,
                                            height=150,
                                            key=f"doc_content_{i}_{len(st.session_state.messages)}",
                                            help="è¿™æ˜¯æ£€ç´¢åˆ°çš„åŸå§‹æ–‡æ¡£å†…å®¹ï¼Œå¤§æ¨¡å‹åŸºäºæ­¤å†…å®¹ç”Ÿæˆç­”æ¡ˆ"
                                        )
                                else:
                                    st.markdown("*ï¼ˆæ­¤æ–‡æ¡£ç‰‡æ®µä¸ºç©ºï¼‰*")
                                
                                # æ˜¾ç¤ºå…ƒæ•°æ®ä¿¡æ¯
                                if doc.metadata and len(doc.metadata) > 1:  # é™¤äº†sourceè¿˜æœ‰å…¶ä»–å…ƒæ•°æ®
                                    with st.expander(f"ğŸ“Š æŸ¥çœ‹æ–‡æ¡£ {i} çš„å…ƒæ•°æ®", expanded=False):
                                        metadata_display = {}
                                        for key, value in doc.metadata.items():
                                            if key != 'source':  # sourceå·²ç»æ˜¾ç¤ºäº†
                                                metadata_display[key] = value
                                        if metadata_display:
                                            st.json(metadata_display)
                                
                                if i < len(result['source_documents']):
                                    st.markdown("---")
                    
                    # ä¹Ÿä¿ç•™ç®€å•çš„æ–‡ä»¶ååˆ—è¡¨ä¾›å¿«é€ŸæŸ¥çœ‹
                    if result['sources']:
                        with st.expander("ğŸ“ æ¥æºæ–‡ä»¶åˆ—è¡¨ï¼ˆå¿«é€ŸæŸ¥çœ‹ï¼‰", expanded=False):
                            unique_sources = list(set(result['sources']))
                            for i, source in enumerate(unique_sources, 1):
                                source_name = source.split('/')[-1] if '/' in source else source
                                st.text(f"{i}. {source_name}")
            
                # ä¿å­˜åŠ©æ‰‹å›ç­”
                st.session_state.messages.append({"role": "assistant", "content": response})
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # é¡µè„š
    st.markdown("""
    <div style="
        background-color: #F8FAFC;
        border: 1px solid #E5E7EB;
        padding: 1.5rem;
        border-radius: 0.5rem;
        text-align: center;
        color: #6B7280;
        margin-top: 3rem;
    ">
        <p style="margin: 0; font-size: 0.9rem;">
            ğŸ† <strong>æ³°è¿ªæ¯ç«èµ›æ™ºèƒ½å®¢æœæœºå™¨äºº</strong> | 
            âš¡ åŸºäº LangChain + Ollama | 
            ğŸš€ ç‰ˆæœ¬ 2.0
        </p>
        <p style="margin: 0.5rem 0 0 0; font-size: 0.8rem; opacity: 0.8;">
            è®©AIåŠ©åŠ›æ‚¨çš„ç«èµ›ä¹‹è·¯ ğŸ¯
        </p>
    </div>
    """, unsafe_allow_html=True)


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1 and sys.argv[1] == "web":
        # Webç•Œé¢æ¨¡å¼
        create_streamlit_interface()
    else:
        # å‘½ä»¤è¡Œæ¨¡å¼
        print("ğŸ¤– LangChain+Ollama æ™ºèƒ½å®¢æœæœºå™¨äºº")
        print("=" * 50)
        
        # åˆå§‹åŒ–æœºå™¨äºº
        try:
            chatbot = LangChainChatbot()
            print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
            # åŠ è½½çŸ¥è¯†åº“
            pdf_files = glob.glob("data/*.pdf")
            if pdf_files:
                print(f"åŠ è½½ {len(pdf_files)} ä¸ªPDFæ–‡ä»¶...")
                if chatbot.load_knowledge_base(pdf_files):
                    print("âœ… çŸ¥è¯†åº“åŠ è½½å®Œæˆ")
                else:
                    print("âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥")
            
            # äº¤äº’å¼é—®ç­”
            print("\nå¼€å§‹é—®ç­”ï¼ˆè¾“å…¥'quit'é€€å‡ºï¼‰:")
            while True:
                question = input("\nè¯·è¾“å…¥é—®é¢˜: ").strip()
                
                if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                    break
                
                if question:
                    result = chatbot.answer_question(question)
                    print(f"\nå›ç­”: {result['answer']}")
                    print(f"ç½®ä¿¡åº¦: {result['confidence']:.2f}")
                    
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
        except Exception as e:
            print(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")


if __name__ == "__main__":
    main() 