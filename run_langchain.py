#!/usr/bin/env python3
"""
LangChain+Ollamaæ™ºèƒ½å®¢æœæœºå™¨äººå¯åŠ¨è„šæœ¬
"""

import os
import sys
import argparse
import subprocess
import requests
from pathlib import Path

def check_ollama_service():
    """æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ"""
    print("ğŸ” æ£€æŸ¥OllamaæœåŠ¡...")
    
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            model_names = [model['name'] for model in models]
            print(f"âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸ï¼Œå¯ç”¨æ¨¡å‹: {model_names}")
            return True, model_names
        else:
            print(f"âŒ OllamaæœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            return False, []
    except Exception as e:
        print(f"âŒ OllamaæœåŠ¡ä¸å¯ç”¨: {e}")
        print("è¯·å…ˆå¯åŠ¨OllamaæœåŠ¡: ollama serve")
        return False, []

def check_required_models():
    """æ£€æŸ¥æ‰€éœ€æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½"""
    print("ğŸ” æ£€æŸ¥å¿…éœ€æ¨¡å‹...")
    
    required_models = [
        "deepseek-r1:7b",
        "mxbai-embed-large:latest"
    ]
    
    success, available_models = check_ollama_service()
    if not success:
        return False
    
    missing_models = []
    for model in required_models:
        if model not in available_models:
            missing_models.append(model)
    
    if missing_models:
        print(f"âŒ ç¼ºå°‘æ¨¡å‹: {missing_models}")
        print("è¯·å…ˆä¸‹è½½æ¨¡å‹:")
        for model in missing_models:
            print(f"  æ‰§è¡Œï¼šollama pull {model}")
        return False
    
    print("âœ… æ‰€æœ‰å¿…éœ€æ¨¡å‹å·²å°±ç»ª")
    return True

def check_dependencies():
    """æ£€æŸ¥Pythonä¾èµ–"""
    print("ğŸ” æ£€æŸ¥Pythonä¾èµ–...")
    
    # åŒ…åæ˜ å°„ï¼špipåŒ…å -> å®é™…å¯¼å…¥å
    package_mapping = {
        'langchain': 'langchain',
        'langchain-ollama': 'langchain_ollama', 
        'langchain-community': 'langchain_community',
        'streamlit': 'streamlit',
        'faiss-cpu': 'faiss',
        'sentence-transformers': 'sentence_transformers',
        'pandas': 'pandas',
        'openpyxl': 'openpyxl',
        'loguru': 'loguru'
    }
    
    missing_packages = []
    
    for package_name, import_name in package_mapping.items():
        try:
            __import__(import_name)
            print(f"  âœ… {package_name}")
        except ImportError:
            print(f"  âŒ {package_name}")
            missing_packages.append(package_name)
    
    if missing_packages:
        print(f"\nâŒ ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡ï¼")
    return True

def check_pdf_files():
    """æ£€æŸ¥PDFæ–‡ä»¶"""
    print("ğŸ” æ£€æŸ¥PDFæ–‡ä»¶...")
    
    import glob
    pdf_files = glob.glob("data/*.pdf")
    
    if pdf_files:
        print(f"âœ… æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶:")
        for pdf_file in pdf_files[:5]:
            print(f"  - {pdf_file}")
        if len(pdf_files) > 5:
            print(f"  ... è¿˜æœ‰ {len(pdf_files) - 5} ä¸ªæ–‡ä»¶")
        return True
    else:
        print("âš ï¸  æœªæ‰¾åˆ°PDFæ–‡ä»¶")
        print("å»ºè®®å°†ç«èµ›PDFæ–‡æ¡£æ”¾åœ¨dataç›®å½•ä¸‹")
        return False

def setup_environment():
    """è®¾ç½®ç¯å¢ƒ"""
    print("ğŸ› ï¸  è®¾ç½®ç¯å¢ƒ...")
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    dirs = [
        "logs",
        "outputs",
        "vectorstore"
    ]
    
    for dir_path in dirs:
        os.makedirs(dir_path, exist_ok=True)
    
    print("âœ… ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ")

# å¯åŠ¨Webç•Œé¢
def run_web_interface():
    """å¯åŠ¨Webç•Œé¢"""
    print("ğŸš€ å¯åŠ¨LangChain+Ollama Webç•Œé¢...")
    
    try:
        subprocess.run([
            sys.executable, "-m", "streamlit", "run", 
            "langchain_chatbot.py",
            "web",
            "--server.address", "127.0.0.1",
            "--server.port", "8501",
            "--browser.gatherUsageStats", "false"
        ])
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")

# å¯åŠ¨å‘½ä»¤è¡Œæ¨¡å¼
def run_command_line():
    """è¿è¡Œå‘½ä»¤è¡Œæ¨¡å¼"""
    print("ğŸ’» å¯åŠ¨LangChain+Ollamaå‘½ä»¤è¡Œæ¨¡å¼...")
    
    try:
        subprocess.run([sys.executable, "langchain_chatbot.py"])
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")

# è¿è¡Œç³»ç»Ÿæµ‹è¯•
def run_test():
    print("ğŸ§ª è¿è¡ŒLangChain+Ollamaç³»ç»Ÿæµ‹è¯•...")
    
    try:
        # ç®€å•æµ‹è¯•
        from langchain_chatbot import LangChainChatbot
        
        print("åˆå§‹åŒ–ç³»ç»Ÿ...")
        chatbot = LangChainChatbot()
        
        print("æµ‹è¯•åŸºç¡€åŠŸèƒ½...")
        result = chatbot.answer_question("æµ‹è¯•é—®é¢˜")
        print(f"æµ‹è¯•ç»“æœ: {result['answer'][:100]}...")
        
        print("âœ… ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

def run_optimized_test():
    print("ğŸš€ è¿è¡Œä¼˜åŒ–RAGç³»ç»Ÿæµ‹è¯•...")
    
    try:
        # æµ‹è¯•ä¼˜åŒ–ç³»ç»Ÿ
        from test_optimized_rag_system import main as test_main
        
        print("å¯åŠ¨ä¼˜åŒ–RAGç³»ç»Ÿæµ‹è¯•...")
        test_main()
        print("âœ… ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…æ‰€æœ‰ä¾èµ–å’Œæ¨¡å‹")

def run_command_line_with_options(use_optimized=True):
    mode_name = "ä¼˜åŒ–æ¨¡å¼" if use_optimized else "ä¼ ç»Ÿæ¨¡å¼"
    print(f"ğŸ’» å¯åŠ¨LangChain+Ollamaå‘½ä»¤è¡Œæ¨¡å¼ ({mode_name})...")
    
    try:
        from langchain_chatbot import LangChainChatbot
        
        # åˆå§‹åŒ–æœºå™¨äºº
        chatbot = LangChainChatbot(use_optimized=use_optimized)
        print(f"âœ… {mode_name}ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        
        # åŠ è½½çŸ¥è¯†åº“
        import glob
        pdf_files = glob.glob("data/*.pdf")
        if pdf_files:
            print(f"åŠ è½½ {len(pdf_files)} ä¸ªPDFæ–‡ä»¶...")
            if chatbot.load_knowledge_base(pdf_files):
                print("âœ… çŸ¥è¯†åº“åŠ è½½å®Œæˆ")
            else:
                print("âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥")
        
        # äº¤äº’å¼é—®ç­”
        print(f"\nå¼€å§‹é—®ç­” ({mode_name}) - è¾“å…¥'quit'é€€å‡º:")
        while True:
            question = input("\nè¯·è¾“å…¥é—®é¢˜: ").strip()
            
            if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                break
            
            if question:
                result = chatbot.answer_question(question)
                print(f"\nå›ç­”: {result['answer']}")
                print(f"ç½®ä¿¡åº¦: {result['confidence']:.2f}")
                if use_optimized and 'optimization_info' in result:
                    print(f"ä¼˜åŒ–ä¿¡æ¯: {result['optimization_info']}")
                
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")

def install_dependencies():
    """å®‰è£…ä¾èµ–"""
    print("ğŸ“¦ å®‰è£…LangChain+Ollamaä¾èµ–åŒ…...")
    
    try:
        subprocess.run([
            sys.executable, "-m", "pip", "install", "-r", "requirements.txt"
        ], check=True)
        print("âœ… ä¾èµ–å®‰è£…å®Œæˆ")
    except subprocess.CalledProcessError as e:
        print(f"âŒ ä¾èµ–å®‰è£…å¤±è´¥: {e}")
        return False
    return True

def pull_ollama_models():
    """ä¸‹è½½Ollamaæ¨¡å‹"""
    print("ğŸ“¥ ä¸‹è½½Ollamaæ¨¡å‹...")
    
    models = ["deepseek-r1:7b", "Qwen2.5-7B-Instruct:latest"]
    
    for model in models:
        print(f"ä¸‹è½½æ¨¡å‹: {model}")
        try:
            subprocess.run(["ollama", "pull", model], check=True)
            print(f"âœ… {model} ä¸‹è½½å®Œæˆ")
        except subprocess.CalledProcessError as e:
            print(f"âŒ {model} ä¸‹è½½å¤±è´¥: {e}")
        except FileNotFoundError:
            print("âŒ æœªæ‰¾åˆ°ollamaå‘½ä»¤ï¼Œè¯·å…ˆå®‰è£…Ollama")
            return False
    
    return True

# å¯æ”¯æŒå‘½ä»¤è¡Œå‚æ•°çš„å¯åŠ¨
def main():
    parser = argparse.ArgumentParser(description="LangChain+Ollamaæ™ºèƒ½å®¢æœæœºå™¨äºº")
    parser.add_argument("--mode", choices=["web", "cli", "test", "optimized"], default="web",
                       help="å¯é€‰è¿è¡Œæ¨¡å¼: web(Webç•Œé¢), cli(å‘½ä»¤è¡Œ), test(æµ‹è¯•), optimized(ä¼˜åŒ–æ¨¡å¼æµ‹è¯•)")
    parser.add_argument("--install", action="store_true", help="å®‰è£…Pythonä¾èµ–")
    parser.add_argument("--pull-models", action="store_true", help="ä¸‹è½½Ollamaæ¨¡å‹")
    parser.add_argument("--check", action="store_true", help="ä»…æ£€æŸ¥ç¯å¢ƒ")
    parser.add_argument("--skip-check", action="store_true", help="è·³è¿‡ç¯å¢ƒæ£€æŸ¥")
    parser.add_argument("--use-optimized", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨ä¼˜åŒ–RAGç³»ç»Ÿ")
    parser.add_argument("--disable-optimized", action="store_true", help="ç¦ç”¨ä¼˜åŒ–RAGç³»ç»Ÿ")
    
    args = parser.parse_args()
    
    print("ğŸ¤– LangChain+Ollama æ³°è¿ªæ¯ç«èµ›æ™ºèƒ½å®¢æœæœºå™¨äºº")
    print("=" * 60)
    
    # å®‰è£…ä¾èµ–
    if args.install:
        if install_dependencies():
            print("âœ… ä¾èµ–å®‰è£…å®Œæˆï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨ç³»ç»Ÿ")
        return
    
    # ä¸‹è½½æ¨¡å‹
    if args.pull_models:
        pull_ollama_models()
        return
    
    # ç¯å¢ƒæ£€æŸ¥
    if not args.skip_check:
        checks_passed = True
        
        # æ£€æŸ¥OllamaæœåŠ¡
        if not check_ollama_service()[0]:
            checks_passed = False
        
        # æ£€æŸ¥æ¨¡å‹
        if not check_required_models():
            checks_passed = False
        
        # æ£€æŸ¥Pythonä¾èµ–
        if not check_dependencies():
            checks_passed = False
        
        # æ£€æŸ¥PDFæ–‡ä»¶
        check_pdf_files()  # ä¸æ˜¯å¿…é¡»çš„ï¼Œåªæ˜¯è­¦å‘Š
        
        if not checks_passed:
            print("\nâŒ ç¯å¢ƒæ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·å…ˆè§£å†³ä¸Šè¿°é—®é¢˜")
            print("\nğŸ’¡ å»ºè®®æ“ä½œ:")
            print("1. å¯åŠ¨OllamaæœåŠ¡: ollama serve")
            print("2. ä¸‹è½½æ¨¡å‹: python run_langchain.py --pull-models")
            print("3. å®‰è£…ä¾èµ–: python run_langchain.py --install")
            return
        
        if args.check:
            print("\nâœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼Œç³»ç»Ÿå¯ä»¥æ­£å¸¸è¿è¡Œ")
            return
    
    # è®¾ç½®ç¯å¢ƒ
    setup_environment()
    
    # æ£€æŸ¥ä¼˜åŒ–æ¨¡å¼å‚æ•°
    use_optimized = True  # é»˜è®¤ä½¿ç”¨ä¼˜åŒ–æ¨¡å¼
    if args.disable_optimized:
        use_optimized = False
        print("â„¹ï¸ ä¼˜åŒ–æ¨¡å¼å·²ç¦ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»ŸRAGç³»ç»Ÿ")
    elif args.use_optimized:
        use_optimized = True
        print("ğŸš€ å¼ºåˆ¶å¯ç”¨ä¼˜åŒ–æ¨¡å¼")
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œ
    if args.mode == "web":
        # Webç•Œé¢ä¼šåœ¨å†…éƒ¨å¤„ç†ä¼˜åŒ–æ¨¡å¼é€‰æ‹©
        run_web_interface()
    elif args.mode == "cli":
        run_command_line_with_options(use_optimized=use_optimized)
    elif args.mode == "test":
        run_test()
    elif args.mode == "optimized":
        run_optimized_test()

if __name__ == "__main__":
    main() 